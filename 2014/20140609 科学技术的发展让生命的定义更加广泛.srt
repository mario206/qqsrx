
1
00:00:11.510 --> 00:00:15.870
说话人 1: 锵锵三人行，好久没见到姚谦兄啊，两位

2
00:00:15.870 --> 00:00:16.470
说话人 2: 好久没见

3
00:00:16.470 --> 00:00:18.310
说话人 1: 哈哈，好久没一年了

4
00:00:18.310 --> 00:00:21.590
说话人 1: 对，一年，咱们是在台北见过一次

5
00:00:21.590 --> 00:00:25.510
说话人 1: 见过，然后在这也一次在这也见，这是去年

6
00:00:25.790 --> 00:00:31.350
说话人 1: 对对对，去年他这个现在说是音乐，著名音乐人退休了

7
00:00:31.350 --> 00:00:31.390
说话人 1: 是

8
00:00:31.430 --> 00:00:37.310
说话人 2: 是是，所以这一年就很多时间就台北北京两地住，尤其在北京时候特别

9
00:00:37.310 --> 00:00:37.630
说话人 1: 自由

10
00:00:37.670 --> 00:00:40.070
说话人 1: 我看到现在变红山军了

11
00:00:40.070 --> 00:00:42.390
说话人 1: 哈哈哈，到北京变红山军

12
00:00:42.390 --> 00:00:49.750
说话人 2: 了，不过在北京的确是什么都可以，叫我干什么我大致都没太多意见，就觉得心里比较自由

13
00:00:49.900 --> 00:00:55.090
说话人 2: 嗯，特别这阵子台北又有什么运动让我很害怕回去

14
00:00:55.570 --> 00:00:56.250
说话人 1: 害怕

15
00:00:56.850 --> 00:01:14.740
说话人 2: 回去你就是忍不住，因为那些都是你的晚辈孩子们，他们做那些事你总是替他担心，但是又不想给予太多的意见，这时候你就老是垫着，那你远距离看就可以客观的看，然后想了不起就微信回应一下就行了

16
00:01:14.780 --> 00:01:16.220
说话人 2: 那还是客观一点，因为

17
00:01:17.140 --> 00:01:19.300
说话人 3: 该有不要在那个局势之

18
00:01:19.300 --> 00:01:21.460
说话人 2: 对添乱，千万不要再添乱

19
00:01:21.700 --> 00:01:31.120
说话人 1: 这本身我就觉得说明台湾的这个文化人哪，实际你还别说多么闲散哈，他们骨子里我觉得还是关心社会的

20
00:01:31.320 --> 00:01:31.440
说话人 1: 那

21
00:01:31.440 --> 00:01:32.920
说话人 3: 当然是吧，他

22
00:01:32.920 --> 00:01:40.720
说话人 1: 你这不像你现在北京这样很，你比如说我是虚无主义者，你学生闹什么事跟我完全没关系

23
00:01:40.920 --> 00:01:53.850
说话人 1: 但是我跟一些台湾朋友谈呐，他们不管是想表示保持距离还是批评还是什么，但是热烈同意，你都会感觉到他心里是关心这些东西，还是关心

24
00:01:53.850 --> 00:01:54.250
说话人 3: 不一样

25
00:01:54.290 --> 00:01:56.380
说话人 3: 那是公民，公民的公民

26
00:01:56.380 --> 00:01:56.740
说话人 1: 意识

27
00:01:56.740 --> 00:01:58.260
说话人 1: 对，他是有公民意识的

28
00:01:58.300 --> 00:02:04.180
说话人 3: 他，你对因为那个地方，那个社会是什么样子你关心，而你关心

29
00:02:04.180 --> 00:02:09.750
说话人 3: 你觉得有价值，是因为你能参与它的行程，它的变化，它的决定

30
00:02:09.910 --> 00:02:14.630
说话人 3: 嗯，但是在我们这儿，在北京就是你关心不关心也都那样

31
00:02:14.630 --> 00:02:15.190
说话人 3: 别就别

32
00:02:15.470 --> 00:02:16.510
说话人 3: 你没听过那句话吗

33
00:02:16.510 --> 00:02:19.410
说话人 3: 叫做天心地命

34
00:02:19.410 --> 00:02:20.090
说话人 1: 吗

35
00:02:20.090 --> 00:02:23.970
说话人 1: 操的是卖白粉的心，卖的是赚的是卖白菜的心

36
00:02:23.970 --> 00:02:26.170
说话人 1: 哈哈哈，对，接近，我听过太阳

37
00:02:26.170 --> 00:02:31.910
说话人 2: 对对对，北京太多有趣的演艺，不过最近我才发觉中文的谚语挺有趣

38
00:02:31.910 --> 00:02:58.330
说话人 2: 那天我在云南还听了一个描述地形的，又描述那种任命感叫说三十五里波 40 李庆，然后二十三十五里坡思施李庆，二十里平路，不用问，就是你永远得翻山，平路就 20 年又得翻山的地形，你的生活都在这里面

39
00:02:58.490 --> 00:03:02.450
说话人 2: 我就常常觉得那某种宿命感，你刚刚说那段也是某种宿命感

40
00:03:02.490 --> 00:03:03.370
说话人 1: 是宿命感

41
00:03:03.410 --> 00:03:09.950
说话人 1: 嗯，所以现在这个谦哥，你看人退了休之后，这是琢磨问题，非常的开阔哈，什么都

42
00:03:09.950 --> 00:03:15.150
说话人 1: 哎呀，他就是自然发展的兴趣，你看我听说为什么今天请他来呢

43
00:03:15.390 --> 00:03:28.640
说话人 1: 他对一个什么事咱们还很少聊他这个兴趣点，他说现在有些新的发明是很科技的，这种东西他特别想说，你觉得为这对我们有什么关系

44
00:03:28.680 --> 00:03:29.040
说话人 1: 有

45
00:03:29.040 --> 00:03:32.520
说话人 2: 其实我最明显是在因为我朋友知道我搜艺术

46
00:03:32.560 --> 00:03:37.570
说话人 2: 是，其实这几年艺术其实有一个最大的是视觉的改变，从

47
00:03:37.570 --> 00:03:40.810
说话人 2: 嗯，摄影的发明时候同时印象派出来了

48
00:03:41.050 --> 00:03:55.020
说话人 2: 可是就像刚我们在录影前说位置的问题，说现在 16: 9，我就当然这个在做电视，可以了解是视频关系，但是我们觉得挺有趣的是不止这些，像 4K 电视出来了

49
00:03:55.140 --> 00:03:58.220
说话人 2: 嗯，像摄影，您到高清已经超过眼睛的时候

50
00:03:58.340 --> 00:04:09.120
说话人 2: 其实美树的绘画，特别是绘画跟雕塑及已有了新的改变，就是有一些东西已经超过你的视觉经验的实物的存在

51
00:04:09.360 --> 00:04:20.980
说话人 2: 而科技最近陆陆续续，其实很久以前从仿生学开始讲，已经很多已经靠超越过人的五官，就是视觉、听觉、触觉的经验

52
00:04:21.060 --> 00:04:33.760
说话人 2: 嗯，但是它是真实的，我们总以为我们看到的，听到它是真实，但客机已经超过我们的感知能力的时候，而产生新的价值观或者新的美术观，这点太有趣

53
00:04:33.760 --> 00:04:49.780
说话人 2: 由于超写实，这是这几年发展的绘画的概念，其实在坦白讲，我们的超写实就是我们现在摄影技术照出来的照片已经到没有可以放到无限的相当的巨大，而且没有看到射点的时候

54
00:04:49.820 --> 00:04:51.980
说话人 2: 嗯，现在 4K 电视已经接近到这

55
00:04:52.020 --> 00:04:53.380
说话人 1: 4K 是什么意思

56
00:04:53.420 --> 00:04:53.860
说话人 1: 4K。

57
00:04:53.860 --> 00:04:56.060
说话人 2: 就是比高清再高清4

58
00:04:56.060 --> 00:04:56.340
说话人 1: 倍

59
00:04:56.540 --> 00:05:00.690
说话人 1: 对，但我觉得你高清眼睛已经超过了你眼睛了

60
00:05:00.690 --> 00:05:02.890
说话人 1: 是他那个到在 4K 还能怎么样

61
00:05:03.090 --> 00:05:09.830
说话人 2: 高清近距离的时候你还看得到观光是 4K 的时候，你看近距离的时候已经没光点了

62
00:05:09.870 --> 00:05:12.110
说话人 2: 但是我们具体看到就是毛细孔

63
00:05:12.110 --> 00:05:19.700
说话人 2: 可是我们作为坦白讲，我看到你这皮肤感觉你有毛细孔，但是可以告诉你一个坑的毛细孔

64
00:05:19.700 --> 00:05:22.780
说话人 2: 对，这已经超越你皮实肉眼的那

65
00:05:22.780 --> 00:05:24.420
说话人 1: 像显微镜的精度了

66
00:05:24.500 --> 00:05:24.780
说话人 1: 对

67
00:05:24.980 --> 00:05:33.290
说话人 2: 所以造成人在再创造绘画，甚至所有动物的生物的进展，其实是跟环境的变化有关系

68
00:05:33.290 --> 00:05:37.490
说话人 2: 嗯，当科技的环境超越你的五官的时候

69
00:05:37.490 --> 00:05:38.450
说话人 2: 嗯，太好玩了

70
00:05:38.450 --> 00:05:50.080
说话人 2: 就好像前阵子就是跟朋友聊这些，然后就得到一个数据，哈利波特里面的魔法现在用科技可以解完成了，已经到三十几个不散了

71
00:05:50.200 --> 00:05:54.630
说话人 2: 最有趣的就是那个大画，旧画框里的画是会动的，实际

72
00:05:54.630 --> 00:05:56.750
说话人 3: 这个就是，这是可以的，这已经完了

73
00:05:56.750 --> 00:05:58.950
说话人 2: 当然可以，现在最厉害是那个斗篷

74
00:05:58.950 --> 00:06:00.510
说话人 3: 的隐身，这也做得到了

75
00:06:00.510 --> 00:06:01.510
说话人 3: 隐形斗篷嘛

76
00:06:01.550 --> 00:06:02.710
说话人 3: 对对对

77
00:06:02.750 --> 00:06:18.830
说话人 2: 对对，当这些东西其实都是在跟我们的已经生物已经拥有的本来的五官的能力以外的时候，那环境的改变就造成我们的进化的改变，就在想我们的进化改变会发展到什么

78
00:06:18.830 --> 00:06:34.340
说话人 2: 我觉得这太有趣的题目，所以我常觉得第一你又很能够聊对一些异常的事情的讨论，说那梁兄又从哲学角度看，我就提出，唉，这个题目在你们两个的观点里面会讨论出

79
00:06:34.340 --> 00:06:35.220
说话人 1: 什么

80
00:06:35.300 --> 00:06:41.220
说话人 1: 你说的这个说是最近在西方有那么一本书叫做失控

81
00:06:41.220 --> 00:06:49.980
说话人 1: 对对对，这个人他好像研究了多少年，实际也有点五迷三道的，经常是一个人这个流浪，这是思考，是这个问题

82
00:06:50.140 --> 00:07:02.540
说话人 1: 但是他这个书很有影响，他提出一个概念叫做第七类生命，好像有个英文的词叫什么 T E C H，什么什么，他就说技术，这是个石破天惊的看法

83
00:07:02.700 --> 00:07:08.240
说话人 1: 嗯，是他认为技术也是生命，嗯，你认为他就是

84
00:07:08.240 --> 00:07:12.520
说话人 1: 嗯，那么也为此他检讨，就是说你认为生命是什么

85
00:07:12.760 --> 00:07:14.720
说话人 1: 比如说有自主的思维

86
00:07:14.760 --> 00:07:28.940
说话人 1: 是啊，他们，那么他就给你抬杠了，他说那么小朋友一岁的小孩，他没有自主的思维，但是他也叫生命，是，唉，他就是这样来推导推导，最后他就在想生命到底是什么

87
00:07:29.070 --> 00:07:35.470
说话人 1: 于是他就认为你比如说现在已经很难分得清楚了，心脏起搏器，嗯是什么

88
00:07:35.710 --> 00:07:44.230
说话人 1: 包括说现在小姑娘们带的那个美瞳，是，但是这美瞳不是属于你的，是不就是他你需要的时候就换加的

89
00:07:44.590 --> 00:07:50.120
说话人 1: 但是现在女孩子就希望你能不能发明一种不用摘的美瞳，嗯，生物的

90
00:07:50.360 --> 00:08:01.480
说话人 1: 嗯，我就一直不但改变我眼睛的颜色，还改变了我的视力，几年我都不用摘下来，嗯，他说这样的发明最多要不了 5 年，嗯就会出现

91
00:08:01.520 --> 00:08:21.340
说话人 1: 嗯，那么到时候你已经很难分得清这个机器技术和人的界限在哪里，甚至他更进一步提出来的就是人下一步要为机器人建立价值观，引导他们做好的机器人，以免将来他们自把自为

92
00:08:21.340 --> 00:08:24.420
说话人 1: 哈哈哈，把我们干掉，就在推演出这么一套体系

93
00:08:24.420 --> 00:08:24.580
说话人 1: 但

94
00:08:24.580 --> 00:08:32.660
说话人 3: 这个其实并不奇怪，你比如说像机器人的伦理，这很多年前就被他就有了，电影都拍过，就是克拉克

95
00:08:32.700 --> 00:08:38.140
说话人 3: 他就已经有所谓机器人三大定律，对，就规定机器人应该怎么做，这跟人的关系

96
00:08:38.510 --> 00:08:51.230
说话人 3: 但现在你刚刚说到机器人的问题或者技术会不会到突破点，这是一个过去 10 年来，我觉得是人类历史上对生命的理解变得最复杂的一个 10 年，最焦虑

97
00:08:51.390 --> 00:08:52.270
说话人 3: 为什么呢

98
00:08:52.310 --> 00:08:58.510
说话人 3: 因为这 10 年没有生物科学，现在已经让我们看到，就重新回头问什么叫生命

99
00:08:58.590 --> 00:09:00.660
说话人 3: 对对，因为说你问生命是怎么样

100
00:09:00.660 --> 00:09:05.420
说话人 3: 我们现在一般说生命就是一种有机化合物，一定是有机化合物才有生命

101
00:09:05.860 --> 00:09:06.540
说话人 3: 那么从什

102
00:09:06.580 --> 00:09:08.300
说话人 3: 但是问题有机化合物怎么来

103
00:09:08.300 --> 00:09:12.030
说话人 3: 一定又是从无机物来，于是现在大家都要重演那段历程

104
00:09:12.270 --> 00:09:12.790
说话人 3: 怎么样

105
00:09:12.790 --> 00:09:18.990
说话人 3: 地球刚开始是怎么从无机对到有机化合物，然后开始产生细胞

106
00:09:18.990 --> 00:09:21.470
说话人 3: 对，我们定义生命，因为为什么细胞最好

107
00:09:21.470 --> 00:09:25.150
说话人 3: 就是因为它要能够有繁殖能力，再造自己的能力

108
00:09:25.150 --> 00:09:27.190
说话人 3: 对，这个这是很关键的定义

109
00:09:27.190 --> 00:09:30.230
说话人 3: 对对对，那么现在我们基本上能够在实验室

110
00:09:30.590 --> 00:09:31.910
说话人 1: 可以在这复制

111
00:09:31.950 --> 00:09:32.630
说话人 3: 把它完全就是

112
00:09:32.630 --> 00:09:34.350
说话人 3: 而且这个复制是怎么样

113
00:09:34.350 --> 00:09:42.060
说话人 3: 复制不是拿你的窦文涛 c 爆出来，不是这样，我们人工造一个生物，现在完全做得到

114
00:09:42.100 --> 00:09:50.420
说话人 3: 嗯，那人终于成为上帝，我们现在是再也不是基因改，不是，甚至不是基因改造是创造生命造物

115
00:09:50.460 --> 00:09:55.700
说话人 3: 那现在的科学家造物，它并不是为了要想虚荣一下当上帝

116
00:09:55.700 --> 00:09:59.500
说话人 3: 是，而是为了要写理解生命的诞生是怎么开始

117
00:09:59.870 --> 00:10:06.830
说话人 3: 那么这个是过程里面就发现所谓的无机跟有机的这条界限其实非常模糊

118
00:10:06.950 --> 00:10:08.670
说话人 3: 是，哎，非常模糊

119
00:10:08.710 --> 00:10:16.610
说话人 3: 那这个模糊之后又想到另一个问题，就跟他讲机器人、机器人，或者是我们讲AI，更准确的讲法就人工智能

120
00:10:17.090 --> 00:10:21.570
说话人 3: 现在这霍金 Steven Hawk 不就谈过这个问题

121
00:10:21.570 --> 00:10:22.410
说话人 3: 他是悲观派

122
00:10:22.650 --> 00:10:30.550
说话人 3: 是，但是无论你乐观悲观也好，都现在必须承认一点，就是寓言中的那个基点快到了singularity

123
00:10:30.950 --> 00:10:43.510
说话人 3: 基点指的是个名词，它指的是到了某一点，我们的 AI 终于产生自我意识，人的点智能点，人工智能产生自我意识，就是说开始意识到我了

124
00:10:43.510 --> 00:10:47.030
说话人 3: 嗯，那一点现在越来越接近了

125
00:10:47.510 --> 00:11:02.340
说话人 3: 以前我记得有预测说是 2040 年就会到达，现在已经有人拉钱，到 2020 年人类就会 AI 发展到那一点，当那天出现之后，当有一个AI，它开始意识到我了，我是谁

126
00:11:02.660 --> 00:11:03.540
说话人 3: 你们是谁

127
00:11:04.340 --> 00:11:10.460
说话人 3: 我们整个生命观念又会变化，所以说过去 10 年这个生命这个东西变得特别

128
00:11:10.460 --> 00:11:10.940
说话人 1: 麻烦

129
00:11:11.300 --> 00:11:15.340
说话人 1: 你看最近有一个电影，我看他们很多女孩爱看，叫赫尔就是

130
00:11:15.420 --> 00:11:16.460
说话人 1: 对对对对

131
00:11:16.460 --> 00:11:19.940
说话人 2: 唉呀，太好电影了，太好，我去年我觉得美国电影剧本写的

132
00:11:19.940 --> 00:11:20.540
说话人 1: 最好的一个

133
00:11:20.660 --> 00:11:21.060
说话人 1: 是吗

134
00:11:21.060 --> 00:11:21.500
说话人 1: 你喜欢

135
00:11:21.500 --> 00:11:21.740
说话人 2: 看

136
00:11:21.780 --> 00:11:24.740
说话人 2: 太喜欢，连音乐、摄影我都太喜欢了

137
00:11:25.180 --> 00:11:30.020
说话人 2: 就是要就像你说的关于人工智慧在发展，就所谓的情感了

138
00:11:30.060 --> 00:11:30.580
说话人 2: 情感

139
00:11:30.780 --> 00:11:37.340
说话人 2: 对，那我们跟一个虚无的坦白讲，他是一个虚拟，就是一个program

140
00:11:37.710 --> 00:11:39.060
说话人 2: 对，嗯，产生感情

141
00:11:39.500 --> 00:11:40.820
说话人 2: 所以你看了是什么感想

142
00:11:40.940 --> 00:11:42.580
说话人 2: 我看了是特别激动

143
00:11:42.620 --> 00:11:51.340
说话人 1: 我看了之后我是觉得我原来认为这个界限是不可逾越的，我原来认为机器永远是机器，是没有自主意志

144
00:11:51.340 --> 00:11:55.870
说话人 1: 是，但是我看了这个电影，我认识到也许是有可能的

145
00:11:56.110 --> 00:12:09.130
说话人 1: 嗯，就比如说他给你找一个陪你聊天的小姐，嗯，他其实输入一些感情的软件，嗯，模式城市，慢慢的，你好像这种东西发展下去，你真不知道是什么

146
00:12:09.130 --> 00:12:14.130
说话人 1: 比如说原来就是说计算机打败这个国际象棋

147
00:12:14.130 --> 00:12:14.850
说话人 1: 嗯，大师叫什么

148
00:12:14.850 --> 00:12:20.940
说话人 1: 卡斯帕罗夫，好像是最后没用几年那个深蓝计算机下棋就赢了他，哈哈哈，又赢了

149
00:12:20.940 --> 00:12:24.660
说话人 1: 下棋就是很复杂，是一些考虑，一些运筹

150
00:12:24.940 --> 00:12:27.740
说话人 1: 那么你说再加入一些感情反应

151
00:12:27.820 --> 00:12:28.780
说话人 1: 嗯，有

152
00:12:28.940 --> 00:12:35.230
说话人 1: 我觉得这需要设计者，它能给人的人类的感情行为

153
00:12:35.230 --> 00:12:35.950
说话人 3: 建立模式

154
00:12:35.950 --> 00:12:38.350
说话人 1: 行为建立某种模式

155
00:12:38.390 --> 00:12:40.470
说话人 1: 嗯，他得是这样可以的

156
00:12:40.550 --> 00:12:47.310
说话人 1: 那事实上这又涉及到一个哲学问题，是人类的这个情感或者什么是有模式的吗

157
00:12:49.430 --> 00:12:52.430
说话人 2: 我不是有模式，是有

158
00:12:52.430 --> 00:13:02.300
说话人 2: 就像计算机现在发展是把我们所有的情绪记忆如果当做 data 来看，是我们一个反应，是很多 data run 出来的，选择一个玩意

159
00:13:02.540 --> 00:13:53.780
说话人 2: 那个赫尔电影我最有兴趣最聚焦的是男，那个男主角吃醋了，当他知道他跟 600 多个人进入感情的恋爱接近恋爱这个情绪关系，他吃醋他解决，因为他是一个就是一个program，他没有肉身，对，然后他的确在精神得到很大的满足，他愿意，就甚至跟朋友宣告他的前任是他了，可是他都可以，就是他没有肉身的欲望了，没有信誉，对，都可以，他可以在只要感情满足，但是当他聚焦在这一点的时候，当他知道他同时在跟 600 多人在谈恋爱时候，他吃醋，他在选择犹豫，可是这个机器人是没有这个顾虑的，对，他没有这个情绪上的困扰，这就是我为晓在人工智慧发展的时候，情绪的问题有没有跟着

160
00:13:54.250 --> 00:14:10.700
说话人 2: 因为你知道它高科技的城市如果运算到一个程度的时候，它是不是人类还没有发展到那么厉害，我们还有会被情绪给困扰，但机器啊，人工智能是没有情绪的困扰时候，那又是另外一个要去面对的问题

161
00:14:10.780 --> 00:14:12.500
说话人 2: 这个电影我就看到这一点，特别

162
00:14:12.500 --> 00:14:12.860
说话人 1: 有兴趣

163
00:14:12.860 --> 00:14:17.300
说话人 1: 你看这个 iPhone 哈，和比最早的手机你就能看到

164
00:14:17.300 --> 00:14:23.270
说话人 1: 就我刚才说的这个西方的那个学者，他的有句话我觉得说的对，就说这个技术

165
00:14:23.350 --> 00:14:27.470
说话人 1: 嗯，任何技术，这个技术的终极是什么

166
00:14:27.470 --> 00:14:34.070
说话人 1: 就是人类为了方便自己创造一个技术，但这个技术要不断完善，它完善的目的是什么

167
00:14:34.070 --> 00:14:34.990
说话人 1: 最终是什么

168
00:14:35.270 --> 00:14:36.950
说话人 1: 最终就是像你一样

169
00:14:37.230 --> 00:14:38.070
说话人 1: 嗯，对吧

170
00:14:38.230 --> 00:14:43.510
说话人 1: 越来越像你一样，最终就像到赫尔这个电影里一样，我希望你就是一个我的女朋友

171
00:14:43.630 --> 00:14:49.950
说话人 1: 对，好，那么最终涉及到这种程度，我认为在一点上就是你说的这个基点会到哪

172
00:14:50.080 --> 00:15:01.760
说话人 1: 我倒不觉得这个机器人哪，他真的能够说自己产生什么意志，但是到时候必须会出现一个类似于量子力学那种选择

173
00:15:01.840 --> 00:15:06.550
说话人 1: 比方说不是比，比方说我找一个我的女朋友，嗯，那就涉及到什么呢

174
00:15:07.030 --> 00:15:11.030
说话人 1: 我说一句话，这个机器人怎么对我反映

175
00:15:11.230 --> 00:15:21.860
说话人 1: 我设想发明这个电脑软件，就发明这种软件，城市的人必定就像下国际象棋一样，它会储存是很多种选项，对吧

176
00:15:22.180 --> 00:15:30.730
说话人 1: 那么一旦出现了这个机器人，它要在很多个选项里随机选择一种的时候，嗯，他就不可控制了

177
00:15:31.130 --> 00:15:34.010
说话人 1: 噢，你，你不可控，你，你不觉得吗

178
00:15:34.010 --> 00:16:00.210
说话人 1: 就是说，比如说你说一句话，如果说我在他的这个电脑里储存 10 种可能的答复，这是有点像那种模糊数理、模糊逻辑，就是说最终如果我授予这个机器人一个权利，嗯，就是他可以在这 10 个回复当中，嗯，任选一个，咱就算到这个时候我认为你就没法对付他了，或者说你，噢，我，你明白吗

179
00:16:00.490 --> 00:16:01.930
说话人 1: 你不知道他会选哪一个

180
00:16:01.930 --> 00:16:02.050
说话人 1: 对

181
00:16:02.130 --> 00:16:08.870
说话人 3: 其实跟其实这并不复杂，现在都已经做得到，但是现在基本上其实问题的焦点在哪

182
00:16:08.870 --> 00:16:27.980
说话人 3: 就我们讲理智也好，讲情感也好、情绪也好，这你从现在比如说认知、科学、脑神经，所以这几门穴位是汇聚在一起的，嗯，从他们角度来看都只不过是我们的大脑皮层，是我们的神经元，他们种种的组织中间的电讯反应而已

183
00:16:28.340 --> 00:16:44.720
说话人 3: 对，但那些东西都是很简单，就是用电脑来换句 0 与一，那假如说我们整个托管或者我们这个制作过程能够复制或者非常逼真的制造出像类似大脑，当然大脑我们说是人最精密的，嗯，世界最精密的机器

184
00:16:44.920 --> 00:16:51.980
说话人 3: 但那基本原理基本构成简单，就是就是反应跟接收反应而已

185
00:16:51.980 --> 00:16:56.820
说话人 3: 对，当我们把这些都能够创造出来的时候，他能不能自己组织

186
00:16:57.060 --> 00:17:00.330
说话人 3: 当他能够自己组织出来的时候，他当然就能做到

187
00:17:00.330 --> 00:17:13.850
说话人 3: 你刚才说那个那种状态已经做得到，那再下来的问题就是他有学习能力，我们不要以为是将来的 AI 就很蠢，就是说他没有感情，比如说他给你，你跟他说你今天心情好吗

188
00:17:14.250 --> 00:17:15.210
说话人 3: 这怎么讲

189
00:17:15.250 --> 00:17:24.250
说话人 3: 那这个他就不知道你回答什么，他会知道，因为他会学习，他经过学习之后他会进步，而且可以学得非常快，进步的非常快

190
00:17:24.670 --> 00:17:31.800
说话人 3: 所以现在问题就来了，就是说到了那一天的时候，那这个我们能不能定义它是生命，它也是人

191
00:17:32.240 --> 00:17:51.580
说话人 3: 而但是问题是现在又有一些新的学说，这是一个过去两年很惹争议的一个学说，是美国的一个做认，也是做认知科学的学者，但是他大胆的挑战到了宇宙学领域，就天文学领域就谈什么呢

192
00:17:51.580 --> 00:17:55.860
说话人 3: 就他说所谓的宇宙会不会有点讲的像佛家了

193
00:17:55.860 --> 00:18:29.390
说话人 3: 有可能必须依赖于人脑的认知才存在，那么它整个讲法有点悬，但中间的关键就是扣在量子力学上面来讲的，那么但这个现在也是惹争论，因为如果他这个讲法成立的话，那么就表示说我们的认知部分的决定了这个宇宙的存在，就假设讲的这个宇宙存在，那么当如果有一套 AI 系统出来之后，他怎么样参与到这个宇宙

194
00:18:29.430 --> 00:18:32.590
说话人 3: 或者说他认知的宇宙是什么样的宇宙

195
00:18:32.950 --> 00:18:35.190
说话人 1: 所以真是很还是去广告吧

196
00:18:35.190 --> 00:18:46.530
说话人 1: 哈哈哈，强三人行广告之后见这个谦哥最近还出了本书，是相遇而已，我要的是那一瞬间，而不是永恒

197
00:18:46.530 --> 00:18:48.330
说话人 1: 哈哈，听上去比较就

198
00:18:48.330 --> 00:19:02.150
说话人 2: 当时取这个书名的时候，编辑一直希望叫咏世间的相应，我说那得 80 岁写才适合，这个书名我承担不起，我就是遇见了，就像今天又有机会来这，又可以听听两位对一件事情的开幕

199
00:19:02.150 --> 00:19:18.500
说话人 2: 我觉得人和人之间互动就在相约说，唉，你得了资讯留住了，变成你以后思考一个又一个数据，像贝塔机器人又多一个贝塔进来以后他思考，所以我一直觉得相遇是起码在有机的，生命在我来说是一个最有趣的事了

200
00:19:18.540 --> 00:19:26.190
说话人 1: 其实就是你刚才讲的，我又觉得又绕回头，你科技发展到这么先进了，你对生命是什么呀

201
00:19:26.190 --> 00:19:34.990
说话人 1: 嗯，你还没弄清楚，我前段时间跟一个医生谈话，他就讲了，说现在其实这个一个人哪怎么算

202
00:19:34.990 --> 00:19:38.610
说话人 1: 生命终结是个相当难办的事情，你知道吧

203
00:19:38.610 --> 00:19:49.820
说话人 1: 就是就说这个医院，比如说我抢救一个人，嗯，你知道，他说现代的这个最先进的医学技术，简直就可以说是接上机器，接上管子，你就活着吧

204
00:19:49.820 --> 00:20:17.500
说话人 1: 对对对对，你说脑死亡，心脏还在跳，对，这这不让，那，你你，你说你呼吸不行了，呼吸不行，安上呼吸机，你能够呼吸，甚至于他说你要不要这个无限的抢救，我有很大的这个可能性，我能让你这具躯体，嗯，在跳动，运行，在运行，你就像是一个人的机器，是你没有任何思想意识或者什么的

205
00:20:17.820 --> 00:20:20.740
说话人 1: 那么你说到底在哪个点上

206
00:20:20.900 --> 00:20:23.930
说话人 1: 你的人算死亡了，生命算消失了

207
00:20:24.530 --> 00:20:31.050
说话人 1: 是，所以就联合你刚才说的机器人的问题，你连人这架机器，嗯，到底算什么

208
00:20:31.090 --> 00:20:34.090
说话人 1: 因为人确实能操纵，我能让你心脏一直跳

209
00:20:34.130 --> 00:20:36.890
说话人 1: 是，甚至于就是说安上心脏起搏器

210
00:20:36.890 --> 00:20:38.560
说话人 1: 是，你不是一直在跳

211
00:20:38.560 --> 00:20:38.680
说话人 3: 吗

212
00:20:38.680 --> 00:20:42.520
说话人 3: 噢，不是，甚至生命的人类生命从哪一刻才叫开始

213
00:20:42.520 --> 00:20:43.920
说话人 3: 你刚才讲的是什么结束

214
00:20:44.000 --> 00:20:45.000
说话人 3: 对，我们才叫开始

215
00:20:45.240 --> 00:20:46.120
说话人 3: 都是有争论的

216
00:20:46.160 --> 00:20:50.800
说话人 3: 对，哲学界里面，比如说我们研做伦理学的人就常常争论的就是剁胎

217
00:20:50.800 --> 00:20:53.040
说话人 3: 是，你说剁胎为什么不行

218
00:20:53.040 --> 00:20:55.080
说话人 3: 就传统讲法是因为是等于杀人

219
00:20:55.120 --> 00:21:01.250
说话人 3: 对，那很简单，马上问题就来，从哪一刻开始受惊暖变叫做人了

220
00:21:01.290 --> 00:21:03.330
说话人 3: 嗯，没错，是受惊力刹那吗

221
00:21:03.410 --> 00:21:06.170
说话人 3: 好像不是，那么胎儿到多大呢

222
00:21:06.170 --> 00:21:11.330
说话人 3: 嗯，那么于是你想想看那个过程，你要断一个点出来说，人就在这时候出现了

223
00:21:11.330 --> 00:21:12.730
说话人 3: 对，哈哈哈

224
00:21:12.730 --> 00:21:17.570
说话人 1: 你要那么说，那我觉得受惊之前我们也很活跃，凭什么就不把我们算人

225
00:21:17.570 --> 00:21:18.690
说话人 1: 哈哈哈，对吧

226
00:21:18.690 --> 00:21:23.730
说话人 1: 哈哈哈哈，整天那么费劲，哈哈哈，容易吗

227
00:21:23.730 --> 00:21:23.890
说话人 1: 有

228
00:21:23.890 --> 00:21:28.650
说话人 2: 个笑话，这虚岁跟实睡是看是从爸爸那头算起来，从妈妈这一头算起来

229
00:21:28.650 --> 00:21:31.330
说话人 2: 唉，对啊，爸爸那头算起就多 10 个亿

230
00:21:31.330 --> 00:21:31.890
说话人 2: 妈妈那头

231
00:21:31.890 --> 00:21:32.210
说话人 3: 多少岁

232
00:21:32.210 --> 00:21:32.930
说话人 3: 那是虚岁

233
00:21:32.930 --> 00:21:33.170
说话人 3: 是

234
00:21:33.170 --> 00:21:35.370
说话人 1: 啊，对，那也是多少亿的人民哪

235
00:21:35.370 --> 00:21:36.130
说话人 1: 你这家伙

236
00:21:36.130 --> 00:21:38.350
说话人 1: 哈哈哈，说葬送了还是潜在

237
00:21:38.350 --> 00:21:38.830
说话人 3: 的人民

238
00:21:38.950 --> 00:21:43.470
说话人 2: 所以科技也让我们对一些生命的价值审美观还有很多重新的思考的机会

239
00:21:43.670 --> 00:21:47.150
说话人 3: 接下来为您播出文明启示录会失控

240
00:21:48.030 --> 00:21:50.900
说话人 1: 就是你还没弄清你自己怎么回事，但是你已经开始
