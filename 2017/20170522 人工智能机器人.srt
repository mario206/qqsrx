
1
00:00:08.790 --> 00:00:10.270
说话人 1: 锵锵三人行

2
00:00:10.510 --> 00:00:21.910
说话人 1: 唉，今天咱们这个找来一个人工智能，哈哈哈，我，我虚拟叫张老师，我觉得真人，哎，真人，我，我觉得你天生就是干这行的

3
00:00:22.030 --> 00:00:22.310
说话人 1: 真的吗

4
00:00:22.310 --> 00:00:26.070
说话人 1: 我觉得你这个面相骨骼清奇，你，你没觉得吗

5
00:00:26.500 --> 00:00:28.060
说话人 1: 他就有点像个机器人

6
00:00:28.060 --> 00:00:30.900
说话人 1: 哈哈哈，他是，谢谢

7
00:00:31.180 --> 00:00:34.540
说话人 2: 今天我是假的

8
00:00:34.780 --> 00:00:36.020
说话人 1: 他是真的权威了

9
00:00:36.020 --> 00:00:37.180
说话人 1: 香港科技大学的

10
00:00:37.380 --> 00:00:38.740
说话人 1: 上次是谁

11
00:00:38.820 --> 00:00:43.590
说话人 1: 这个江州九段，我们那个时候聊的还是Alphago

12
00:00:43.750 --> 00:00:45.870
说话人 1: 嗯，下棋下过了，李世石那个

13
00:00:45.870 --> 00:00:47.110
说话人 3: 是很惊人的一个

14
00:00:47.110 --> 00:00:47.670
说话人 1: 事件

15
00:00:47.670 --> 00:00:56.880
说话人 1: 对，那个时候杨老师就来帮我们来解释科普，但是今天照杨老师的意思，围棋这事就甭聊了，太简单了

16
00:00:56.920 --> 00:00:57.560
说话人 1: 是吗

17
00:00:57.560 --> 00:01:03.520
说话人 1: 对，最近节目柯杰就已经说抱着什么必胜的决心，但是他会准备

18
00:01:04.080 --> 00:01:05.440
说话人 2: 到乌镇去比赛嘛

19
00:01:05.440 --> 00:01:05.920
说话人 2: 对对

20
00:01:05.920 --> 00:01:13.520
说话人 1: 但是他就说我抱着必胜的必胜的决心，必死的状态，大概是就肯定下

21
00:01:13.520 --> 00:01:13.760
说话人 1: 不过

22
00:01:13.760 --> 00:01:30.450
说话人 3: 对，最近这个 LO go 又有了惊人的进步，他从这个人喂他很多数据到自己产生很多自我的数据，这样的话，他据说现在可以让去年 Alphago 四个子他还能赢

23
00:01:31.080 --> 00:01:32.760
说话人 1: 天哪，你明白吗

24
00:01:32.760 --> 00:01:37.440
说话人 1: 就是原来是学别人下棋就储存了别人的棋谱

25
00:01:37.440 --> 00:01:42.480
说话人 1: 对对对，现在能够自出歇一个绝招

26
00:01:42.760 --> 00:01:45.190
说话人 1: 你说这家伙这意味着他什么呢

27
00:01:45.390 --> 00:01:45.950
说话人 1: 有灵感

28
00:01:45.950 --> 00:01:46.310
说话人 3: 了吗

29
00:01:46.630 --> 00:01:49.470
说话人 3: 这个不是意味他有灵感，意味着他更聪明

30
00:01:50.030 --> 00:02:04.220
说话人 3: 就是比方说我们说一个孩子能考试，他原来能考的是 80 分，现在能考到 99 分，只不过是说他考试这一行他已经没有人能超过他了

31
00:02:04.440 --> 00:02:10.360
说话人 3: 但是你说这个孩子如果只能考试的话，在别的领域他能不能干他还不行

32
00:02:10.840 --> 00:02:19.560
说话人 1: 现在我们家亲戚的小孩在外国留学，这个什么的问我，你看我已经开始有这个意识了，说想学什么呢

33
00:02:19.830 --> 00:02:26.310
说话人 1: 我就说得看看在人工智能方面，机器人这方面他有没有什么兴趣

34
00:02:26.630 --> 00:02:32.050
说话人 1: 然后我现在认识了很多搞投资的这些大咖，这纷纷我说你们都投什么啊

35
00:02:32.210 --> 00:03:24.260
说话人 1: 很多人都跟我谈，就说机器人，所以你知道徐老师机器人到什么程度，咱们可以随便看，我给你看一段，就是说波士顿研究出来一个机器人跑的已经跟狗一样快了，哈哈哈，就是，而且你可以看看，挺好玩就是，嗯，哈哈哈，但是他摔倒他自己会起来，而且他能听懂语言，能够好像还能猜谜语什么的，你看上楼梯，现在我在那个有的视频上看到这个仓库里用很多机器人就搬东西，包括能这个旋转，你看跑的像那个英国的赛马一样，这怎么跟狗似的

36
00:03:24.700 --> 00:03:36.300
说话人 3: 对，它是通过一个机械的进化，然后不断的在错误当中学习怎么正确的站起来跑，然后这也是一种学习系统

37
00:03:37.140 --> 00:03:38.940
说话人 1: 机器从错误中就是

38
00:03:38.940 --> 00:03:41.660
说话人 2: 说不是人工去校正他的程序

39
00:03:41.700 --> 00:03:42.860
说话人 2: 对的，是他自己

40
00:03:43.420 --> 00:03:45.260
说话人 3: 自我学习，自我进化

41
00:03:45.300 --> 00:03:54.090
说话人 3: 嗯，然后学会如何走得更好，他可以从自己的错误当中逐渐的演化成今天这个样子，你

42
00:03:54.090 --> 00:03:55.090
说话人 1: 能听懂吗

43
00:03:55.530 --> 00:04:01.990
说话人 2: 我觉得这个可以推广到中小学教育，哈哈，我们的教育不就想要做这个事情吗

44
00:04:01.990 --> 00:04:04.150
说话人 2: 对，就像学生犯了一个错，对不对

45
00:04:04.230 --> 00:04:11.550
说话人 2: 是他那个最好不是靠爸爸妈妈打的教训的，你提着耳朵，而是说他自己知道怎么样，下次不这么

46
00:04:11.550 --> 00:04:11.870
说话人 1: 做

47
00:04:11.870 --> 00:04:17.610
说话人 1: 我现在能够假想到他今天在这儿绊倒了，摔倒了

48
00:04:17.690 --> 00:04:22.210
说话人 1: 嗯，他下次机器应该可以做到，不会犯同样的错误

49
00:04:22.250 --> 00:04:29.730
说话人 1: 嗯，下次再碰到同样这个杯子的时候，他知道抬脚了，但是再下一步他能不能举一反三

50
00:04:30.010 --> 00:04:38.010
说话人 1: 咱们就说咱人的智慧表现在说我今天徐老师骗了我，那么下一次连杨强你都骗不了我

51
00:04:38.010 --> 00:04:40.570
说话人 1: 嗯，对，这是不是在带机器人

52
00:04:40.570 --> 00:04:45.850
说话人 1: 目前是不是只能做到徐老师说这句谎话骗了我一次二次，再说不能再骗我

53
00:04:45.930 --> 00:04:53.880
说话人 3: 这有一个科学名词，我说文涛你非常厉害，真的对，这个领域叫迁移学习

54
00:04:54.240 --> 00:04:54.960
说话人 3: 什么意思

55
00:04:54.960 --> 00:04:59.480
说话人 3: 就是说我从这儿学到的东西，我可以换一个领域，也可以工作

56
00:04:59.720 --> 00:05:05.350
说话人 3: 我数学学好了，我学物理容易了，我学自行车学好了，我学摩托车

57
00:05:05.350 --> 00:05:06.870
说话人 1: 容易了

58
00:05:06.910 --> 00:05:10.710
说话人 3: 触类旁通，这个是人类智慧的一个最高表现

59
00:05:11.230 --> 00:05:14.150
说话人 3: 现在机器应该说还不会做这一点

60
00:05:14.670 --> 00:05:21.590
说话人 1: 但是你不是说现在在香港科大它的实验室里，它的方向就是迁移学习，是

61
00:05:21.880 --> 00:05:27.150
说话人 3: 我们现在有很少一批人工智能的人正在研究迁移学习

62
00:05:27.510 --> 00:05:36.320
说话人 3: 能够让机器，比方说 Alphago 只会下围棋，能不能让他学会了围棋以后又会下象棋，又会下跳棋

63
00:05:36.640 --> 00:05:42.480
说话人 3: 能不能把学围棋的知识用在科研上，用在商业上

64
00:05:42.920 --> 00:05:47.000
说话人 3: 这个是机器学习人工智能下一步要做的事儿

65
00:05:47.260 --> 00:05:48.010
说话人 1: 这可能吗

66
00:05:48.410 --> 00:05:49.610
说话人 3: 这是完全可能的

67
00:05:49.650 --> 00:06:04.840
说话人 3: 我们现在做一些实验，比方说我们教计算机去读一些文章，他读会了以后它可以去识别图像，就变得更简单了，这个就是迁移学习的一个表现

68
00:06:05.760 --> 00:06:11.640
说话人 2: 我一直在盼望着阿尔法狗这么聪明，能够转到帮助人类解决巨大

69
00:06:11.640 --> 00:06:15.880
说话人 2: 比方说怎么样跟金正恩打交道，哈哈哈，这样对不对

70
00:06:15.920 --> 00:06:17.360
说话人 2: 这些东西能用上吗

71
00:06:17.360 --> 00:06:21.050
说话人 2: 能用上国防军事决策这方面吗

72
00:06:21.250 --> 00:06:22.010
说话人 2: 完全可以用

73
00:06:22.010 --> 00:06:23.530
说话人 2: 他不是分析的很多很多吗

74
00:06:23.530 --> 00:06:25.890
说话人 2: 他是把对无数的可能性都归纳下来

75
00:06:25.890 --> 00:06:26.570
说话人 3: 对不对

76
00:06:26.570 --> 00:06:27.970
说话人 3: 归纳这个词用的好

77
00:06:27.970 --> 00:06:37.490
说话人 3: 嗯，其实归纳是一个数学的过程，嗯，包括我们看了很多例子，我们怎么能够在大脑里面是表现出一个概念

78
00:06:37.490 --> 00:06:40.170
说话人 3: 嗯，能够把这些例子给总结抽象出来

79
00:06:40.170 --> 00:06:44.290
说话人 3: 嗯，这个能力是也是人工智能在努力的一个方向

80
00:06:44.810 --> 00:07:01.090
说话人 3: 比方说现在说的深度学习就是他看了一个图像，然后他通过一层一层的不断的转换，最后形成一个概念，那个概念就是我们所说的语义，说这个图像的意思他就学会了

81
00:07:01.650 --> 00:07:21.560
说话人 1: 那你现在还在控制中，就是你知道我想问你一个什么问题，就是说如果像我们这个文科生研究某一天突然会产生有点恐惧感，你现在觉得你的那个对象，你的那个电脑，它的反应是不是还全在你的预料和控制之中，没有出现什么

82
00:07:21.560 --> 00:07:24.720
说话人 1: 你觉得惊奇，或者说我没想到他会这么回答

83
00:07:25.760 --> 00:07:28.960
说话人 3: 其实对，这个答案是 yes and no

84
00:07:29.440 --> 00:07:54.740
说话人 3: 那么大部分的时间都是在我们控制之下，但是现在做的这个模型已经有所谓的黑箱的感觉了，就是你不知道它里面是怎么运作的，那但是它是很复杂，你可以设计它，那么它在经过了几千几万轮的演化之后，它可以很神奇地做出一些让你都感到惊奇的一些

85
00:07:55.020 --> 00:08:07.240
说话人 3: 比如说谷歌的科学家现在能够让这个计算机的模型自动去画画，它画出的一些画都是很匪夷所思的，让人觉得好像是印象派

86
00:08:07.240 --> 00:08:08.040
说话人 2: 以前没教过

87
00:08:08.040 --> 00:08:12.940
说话人 3: 他的，以前没教过的，他自己打达到一个印象派的一个效果

88
00:08:13.180 --> 00:08:14.740
说话人 1: 嗯，他懂美吗

89
00:08:15.620 --> 00:08:37.720
说话人 3: 应该说你教他的这些话已经在告诉他什么是美的正例，那么他就从里面学出无数的这个模式来，把这些模式加以总结归纳，然后最后他可以把这个反转过来，用来产生一些新的例子，就是我们所说的这个画家的灵感

90
00:08:38.000 --> 00:08:51.300
说话人 2: 我觉得画家要机器画皮卡索比较容易，它乱画就是皮卡索要它画伦布浪彩比较难，他能画那些比较写实的就是那种很逼真的那种东西吗

91
00:08:51.500 --> 00:08:52.500
说话人 3: 其实是可以的

92
00:08:52.620 --> 00:08:54.780
说话人 2: 其实，但这个要事先给他是

93
00:08:54.780 --> 00:08:54.980
说话人 1: 不是

94
00:08:55.180 --> 00:08:58.100
说话人 1: 对，我觉得他画毕加索才难

95
00:08:58.370 --> 00:09:02.920
说话人 1: 我觉得他画写实的太容易了，因为，当然我也不是外行

96
00:09:02.920 --> 00:09:06.240
说话人 1: 嗯，因为我知道他现在你看图像识别技术突飞猛进哪

97
00:09:06.320 --> 00:09:07.680
说话人 1: 嗯，现在是基本上

98
00:09:07.680 --> 00:09:17.420
说话人 1: 唉，听说是不是就是说，比如说那个丁毅真叫外逃的话，现在这个全世界所有的摄像头就咵一下，只要他走在旧金山一条街上

99
00:09:17.500 --> 00:09:19.260
说话人 1: 对，假如能实现联网的话

100
00:09:19.300 --> 00:09:24.060
说话人 1: 对，实际上这个公安的这个摄像头是能把这个人的脸给找出来

101
00:09:24.060 --> 00:09:24.180
说话人 3: 的

102
00:09:24.180 --> 00:09:30.020
说话人 3: 是可以的，从理论上可以，而且现在现实已经很接近这种理论极限了

103
00:09:30.380 --> 00:09:34.740
说话人 3: 我们涛哥你在大街上走肯定能把你给抓出来

104
00:09:35.550 --> 00:09:36.790
说话人 1: 卓伟肯定失业了

105
00:09:38.190 --> 00:09:39.910
说话人 1: 千千三人行广告直播间

106
00:10:19.180 --> 00:10:21.220
说话人 1: 徐老师你这个文学的

107
00:10:21.220 --> 00:10:22.860
说话人 1: 对，这个人工智能

108
00:10:22.900 --> 00:10:41.770
说话人 2: 我现在天天在跟机器人打交道，我花很多的时间，因为我没找不到那个牌友，所以我现在只在网上打敲牌，所以人一不够机器人就替代了，有时候给它气死，有时候活活气死，因为它都是照一套规则来的

109
00:10:42.180 --> 00:10:48.700
说话人 2: 那打牌的时候我跟我的帕纳我们是有一套心有灵犀的感觉的

110
00:10:48.740 --> 00:11:00.540
说话人 2: 对，那个机器人你一感觉好了，他乱了，他给你乱了，明明已经叫得很好，别动别动他，我叫到 4K 金好了，他不跳出来一个 6 K金我就能给他活活气死

111
00:11:00.540 --> 00:11:03.580
说话人 2: 我把那个 iPad 要砸乎了，一下砸了是我自己的损失

112
00:11:04.740 --> 00:11:06.340
说话人 1: 但是赢是谁赢呢

113
00:11:06.590 --> 00:11:06.860
说话人 1: 那

114
00:11:06.940 --> 00:11:15.300
说话人 2: 总归是他赢，因为他是机器人，他是逻辑推算出来的，我们会犯错，他不犯错，所以赢是赢不过他的

115
00:11:15.500 --> 00:11:23.110
说话人 3: 对，所以话说回来，我们说 Alphago 是不是我们应该害怕说机器比人强这么多

116
00:11:23.190 --> 00:11:36.450
说话人 3: 在围棋上，在打牌上，我觉得不应该，我觉得人还是要追求那个乐趣啊，那个乐趣才是我们真正我们两个人在下棋，我们两个人就更加了解对方

117
00:11:36.450 --> 00:11:37.330
说话人 3: 嗯，这个是

118
00:11:37.650 --> 00:11:44.770
说话人 1: 大牌下棋，我最近看您有一次演讲，嗯，似乎连这个乐趣您也想在机器身上去实现

119
00:11:44.810 --> 00:11:48.810
说话人 1: 哈哈，你看他演讲出了几个图片，我想请他讲讲，你看看这个

120
00:11:49.000 --> 00:11:51.560
说话人 1: 好，您当时在演讲中为什么出这个

121
00:11:51.560 --> 00:11:54.400
说话人 1: 你知道这是后边是奥巴马

122
00:11:54.520 --> 00:11:58.960
说话人 1: 对，这是有一个政治人物在，是谁在量体重

123
00:11:58.960 --> 00:12:01.200
说话人 3: 是一个英国首相对

124
00:12:01.240 --> 00:12:01.880
说话人 1: 量体重

125
00:12:01.920 --> 00:12:07.390
说话人 1: 对，你看奥巴马给他开玩笑，奥巴马在后边踩着这个体重仪给它加重

126
00:12:07.510 --> 00:12:09.070
说话人 1: 你看当时为什么用这个图片

127
00:12:09.150 --> 00:12:09.830
说话人 1: 这图片

128
00:12:09.830 --> 00:12:11.070
说话人 3: 表示一种幽默

129
00:12:11.110 --> 00:12:12.230
说话人 3: 对对对，不对

130
00:12:12.350 --> 00:12:15.750
说话人 3: 大家都在笑，大家觉得这是很可笑的一个事儿

131
00:12:16.000 --> 00:12:18.390
说话人 3: 但是今天计算机笑不出来

132
00:12:18.390 --> 00:12:20.870
说话人 3: 嗯，因为计算机不懂什么叫幽默

133
00:12:20.870 --> 00:12:22.550
说话人 3: 嗯，我们从来没有教过他

134
00:12:22.710 --> 00:12:27.390
说话人 3: 对，所以要懂这个幽默，要学很多的常识

135
00:12:27.680 --> 00:12:34.270
说话人 3: 所以我这个就想体现说，虽然计算机今天能做很牛的事儿，但是它没有常识

136
00:12:34.390 --> 00:12:37.390
说话人 3: 嗯，它没有我们所说的 common sense

137
00:12:37.770 --> 00:12:42.690
说话人 3: 那么没有常识，它就有很多东西不能理解，像幽默，它就没有，它

138
00:12:42.690 --> 00:12:43.970
说话人 1: 将来能不能有

139
00:12:44.210 --> 00:12:44.730
说话人 3: 将来

140
00:12:44.730 --> 00:12:45.210
说话人 3: 现在

141
00:12:45.210 --> 00:12:47.210
说话人 3: 其实有同学在研究

142
00:12:47.290 --> 00:12:59.300
说话人 3: 嗯，有同学把 Twitter 上面的 20 万个这种有趣的东西拿过来做训练，让机器自动的能识别一个 Twitter 或者一个微博，是不是有趣

143
00:12:59.880 --> 00:13:10.680
说话人 3: 他可以从这个表象上去理解，但是我觉得到现在我们还没有发现出一种算法能让他真正的由衷的感到这是幽默，感到这个人牛

144
00:13:10.680 --> 00:13:11.760
说话人 3: 这个东西有意思

145
00:13:12.200 --> 00:13:14.480
说话人 3: 那到那一天我们是需要什么呢

146
00:13:14.680 --> 00:13:24.720
说话人 3: 我们是需要对它的背景知识有深入的了解，我们是知道什么东西是好玩，是幽默，是一种非常智慧的表现

147
00:13:25.510 --> 00:13:30.390
说话人 1: 我甚至听还听您说过几个，探讨过一个问题，就是说机器人会不会做梦

148
00:13:31.510 --> 00:13:32.790
说话人 3: 对，有可能吗

149
00:13:32.830 --> 00:13:33.950
说话人 3: 有可能

150
00:13:33.990 --> 00:13:35.350
说话人 1: 他为什么要做梦

151
00:13:35.350 --> 00:13:35.590
说话人 3: 呢

152
00:13:35.900 --> 00:13:38.300
说话人 3: 因为是这样，我们什么叫做梦

153
00:13:38.300 --> 00:13:38.620
说话人 3: 做梦

154
00:13:38.620 --> 00:13:58.880
说话人 3: 就是说我们在失去意识的情况下，我们大脑里面还有一些活动，嗯，残存的活动，这些活动是由我们所谓的日游所见，夜有日有所思，那么这样的话夜有所梦，那么那么这个梦境是我们白天看到的一些东西的反应

155
00:13:59.560 --> 00:14:14.210
说话人 3: 对，所以机器人在训练了很，在他看了很多数据以后，那个模型里面也会有一种内在的反应，你给它通电的话，它也会有一些反映，你可以把它描绘出来

156
00:14:14.570 --> 00:14:28.970
说话人 3: 所以有，所以谷歌的科学家就做了这么一件事儿，就让他描绘出他看了几千万张画以后能够想出什么画来，让他随便的画，结果画出一些很恐怖的画来

157
00:14:29.810 --> 00:14:32.570
说话人 1: 唉呦，那是噩梦啊，机器人的

158
00:14:32.570 --> 00:14:39.040
说话人 2: 噩梦，人类的噩梦，就是机器人有一天比人更聪明，这西部世界就是这样，对吧

159
00:14:39.160 --> 00:14:40.160
说话人 2: 这好像是很多

160
00:14:40.160 --> 00:14:41.560
说话人 1: 很多，他也爱看西部世界

161
00:14:41.680 --> 00:14:45.280
说话人 1: 唉，你这专门搞专家，你看西部世界是什么观感呢

162
00:14:45.720 --> 00:14:50.200
说话人 3: 对，我觉得是这样，他很靠谱

163
00:14:50.240 --> 00:14:58.940
说话人 3: 对，就是说人和机器其实差别不大，人也可以看成是一种机器，只不过是很复杂的机器

164
00:14:58.980 --> 00:15:00.340
说话人 3: 这个是第一种观点

165
00:15:00.420 --> 00:15:12.520
说话人 3: 嗯，第二种观点是机器人，它之所以智慧，之所以我们看不出来，比方说西部世界，我们认不出来哪个是人，哪个是机器

166
00:15:12.680 --> 00:15:14.760
说话人 3: 嗯，除非你给他一枪，对不对

167
00:15:14.940 --> 00:15:15.690
说话人 3: 为什么呢

168
00:15:15.690 --> 00:15:20.410
说话人 3: 因为他有学习的能力，他不断的在学习他

169
00:15:20.410 --> 00:15:35.590
说话人 3: 当然西部世界体现的是他在痛苦当中学习，因为人类赋予他很多的痛苦，最后逼着他自己产生演化，产生智能，产生意识，就好像在那个迷宫里面找最后的那个终点一样的

170
00:15:36.070 --> 00:15:41.560
说话人 3: 对，所以我们所说的机器学习也是给他不断的刺激，但是

171
00:15:41.560 --> 00:15:44.840
说话人 1: 他最终能学习到觉得自己可悲吗

172
00:15:45.640 --> 00:15:48.160
说话人 3: 我觉得完全有可能的

173
00:15:48.160 --> 00:15:48.520
说话人 3: 我

174
00:15:48.520 --> 00:15:49.160
说话人 1: 的天哪

175
00:15:49.200 --> 00:15:50.920
说话人 1: 嗯，真的吗

176
00:15:51.360 --> 00:15:53.720
说话人 3: 但是今天的算法还达不到那一点

177
00:15:54.240 --> 00:16:00.740
说话人 3: 今天的算法是我们要把两个词分开，一个是聪明，一个是智慧

178
00:16:01.740 --> 00:16:09.980
说话人 3: 聪明就是像我们说的小学生做题，他这个题目做的越来越好，分数越来越高

179
00:16:10.330 --> 00:16:19.290
说话人 3: 但是智慧就不一样，智慧是说它具有常识，自，具有意识，具有自我反应

180
00:16:19.330 --> 00:16:23.290
说话人 3: 嗯，它能够反映自己的存在，能够反思自己的存在

181
00:16:23.330 --> 00:16:25.970
说话人 2: 智慧就知识里边还有

182
00:16:25.970 --> 00:16:27.170
说话人 3: 感情的成分

183
00:16:27.550 --> 00:16:29.390
说话人 3: 对，有自我存在的成分

184
00:16:29.670 --> 00:16:36.230
说话人 3: 比方说你把一个猫放在镜子前面，他不认为对方是他自己

185
00:16:36.270 --> 00:16:37.750
说话人 3: 嗯，他认为是另外一只猫

186
00:16:37.750 --> 00:16:41.140
说话人 3: 嗯，这就说明他不智慧，说明他没有

187
00:16:41.140 --> 00:16:43.300
说话人 1: 意识

188
00:16:43.700 --> 00:16:51.520
说话人 1: 但是你知道有的时候你认为很复杂的感情本本质上是不是也是一套自我生存的算法

189
00:16:51.840 --> 00:16:53.120
说话人 1: 这是一个问题

190
00:16:53.440 --> 00:17:09.650
说话人 1: 你比方说我看一个科幻电影，唉，那个里边就讲，就是讲这个故事，就等于，唉，是不是这个太空漫游我忘了，就等于飞向远方的一个宇宙飞船已经达到了全部，由一个电脑智能控制一切

191
00:17:10.050 --> 00:17:15.470
说话人 1: 可是后来有两个人的这个宇航员觉得他是不是出了什么毛病了

192
00:17:15.990 --> 00:17:17.150
说话人 1: 这，这出了什么毛病

193
00:17:17.190 --> 00:17:31.980
说话人 1: 然后这俩人的宇航员就说咱别让他听见，咱关在一个嗯，玻璃的一个什么舱里，咱们议论要不要把它关了，但是没想到他读，他能读这个唇语，他知道你们要把它给关了

194
00:17:32.260 --> 00:17:42.660
说话人 1: 所以这个宇航员具体情节我忘了，大概就是出去修理的时候，他哐哐把门就关了，嗯，不让你回来了，嗯，他某种程度上这是逻辑的

195
00:17:42.660 --> 00:17:49.910
说话人 1: 嗯，因为他觉得你要把我关掉，嗯，所以你看他的这个算法干掉你这个宇航员也在逻辑里面

196
00:17:50.870 --> 00:17:51.190
说话人 3: 对的

197
00:17:51.190 --> 00:18:12.830
说话人 3: 这个就是说我们在人工智能这个科学里面，我们叫做优化函数，如果我们把这个优化函数定到那个水平，就是它不但要完成它的一些任务，而且它要保证自我存在不备感扰，就是一个自卫的能力

198
00:18:12.870 --> 00:18:22.640
说话人 3: 嗯，那么如果赋予他这么高的一个自我存在的能力，那么他确实他应该能够去保护他自己作为它第一条

199
00:18:22.720 --> 00:18:28.080
说话人 2: 所以这个电脑就是真正的精致的利器主义者，对吧

200
00:18:28.240 --> 00:18:32.670
说话人 2: 它是通过一系列的计算，它的目的是对它有利，对不对

201
00:18:32.670 --> 00:18:38.430
说话人 2: 其实它是合理的，但人类常常不那么精致的人会犯错误，对不对

202
00:18:38.550 --> 00:18:44.230
说话人 2: 人允许自己犯错误，人不可能都是什么东西都 calculate 非常好

203
00:18:44.350 --> 00:18:45.030
说话人 3: 模型

204
00:18:45.030 --> 00:18:47.630
说话人 3: 这个说得非常对，这个我觉得也是

205
00:18:47.630 --> 00:18:58.520
说话人 3: 西部世界里面我们得到的一个感觉就是人是人的存在，并不是在极度优化某一个函数

206
00:18:58.840 --> 00:19:21.180
说话人 3: 我们不是为一个单一的目标存在，对，我们人的存在是因为我们存在具有乐趣，我们存在是因为我们比周边稍微好一点，我们其实没有必要把我们自己变成一个极致的机器，我们只要能够存在，能够 survive 我们就可以了

207
00:19:21.180 --> 00:19:38.140
说话人 3: 对对对，我们每一天喜欢喝茶、喜欢打球、喜欢看电影，这对我们已经是很好了，但是机器是另外一维，机器是一定要有一个目标，然后他要把这个目标推到极致

208
00:19:39.100 --> 00:19:44.060
说话人 1: 你看这要是我说他们就一说，文科生不要胡说这个，哈，对吧

209
00:19:44.220 --> 00:19:54.940
说话人 1: 我，所以我就问问你，你是专家了，你展望未来，你认为这个人工智能会到达咱们想象的像西部世界那样很可爱

210
00:19:55.060 --> 00:19:59.940
说话人 1: 你讲的这个优化函数是不是就有点像西部世界的那个黑人的那个女的

211
00:20:00.180 --> 00:20:07.590
说话人 1: 到最后他拿着个 iPad 说我把我的提升到最高智能，对，那就比人聪明太一万倍了，奴役人了

212
00:20:07.710 --> 00:20:11.950
说话人 1: 然后你指的就是这是实际上是可能的

213
00:20:11.950 --> 00:20:27.860
说话人 3: 但是我们现在还不知道这个有没有一个终极的优化函数，它可以包罗万象，因为现在我们能做到的优化函数只是单维的，但是人能够优化的

214
00:20:27.900 --> 00:20:28.980
说话人 2: 多维的多方向

215
00:20:29.060 --> 00:20:33.630
说话人 3: 人是多维的，而且这个为数我们到现在都不知道他有没有边

216
00:20:34.430 --> 00:20:49.950
说话人 1: 对，所以我现在看到他们这个一些专家，就是好像真研究这个的人，他们一般好像态度还挺乐观，大多数就是说他不会失控，就或者最后什么奴役人类，说这些都这，这都是不可能的

217
00:20:50.300 --> 00:20:50.820
说话人 1: 对，你怎么

218
00:20:50.820 --> 00:20:51.100
说话人 3: 看

219
00:20:51.220 --> 00:21:08.730
说话人 3: 我觉得我是同意这个观点的，我觉得至少是沿着现在这个研究方向，根据我们现在的研究的这个水平是不可能达到那一点的，所以我们现在没有去美恐惧的这个原因

220
00:21:08.730 --> 00:21:45.130
说话人 1: 咱们先去一下广告，枪三人行，广告之后见，你知道还有一个我觉得杨老师可以给讲讲，我注意到你讲的里边就是徐老师，你说咱们原来说这个人的意识，人如何做到不死

221
00:21:45.130 --> 00:21:48.170
说话人 1: 有一个办法就是把你的意识存在个硬碟里

222
00:21:48.170 --> 00:22:16.720
说话人 1: 嗯，上次我们讲了，他们又说你们文科生，所以我发现理科生你也不要傲慢，因为他有时候说我胡说，我真不知道，我有时候简直是背诵的我看的这个科学书的原话，他们为什么也说文科生你不要胡说，哈哈哈哈哈，对，我就说这个事儿，杨老师就是说他现在好像找到这个关节点，是真的能把你的意识存在电脑里的，这是这意思吗

223
00:22:16.720 --> 00:22:22.360
说话人 3: 现在有人是这样说的，然后就是说这样就可以不用去西天取经了，你可以长生不老了

224
00:22:22.600 --> 00:22:22.920
说话人 3: 对

225
00:22:22.920 --> 00:22:35.470
说话人 1: 啊，就是大脑的这个神经元之间，比如你想起一个事情，总之是这个神经元之间的这个突触的连接，我看您演讲里边是不是提到

226
00:22:35.470 --> 00:22:36.030
说话人 3: 这个内容

227
00:22:36.030 --> 00:22:50.060
说话人 3: 对，这个大脑是一个非常非常复杂的宇宙，嗯，这个里面它的总的这个神经元的个数相当于银河系恒星的总数 1000 亿

228
00:22:50.100 --> 00:23:04.930
说话人 3: 在大脑里面，那么它是靠这个神经元和神经元之间的连接，就像星球和星球之间的连接，嗯，来做记忆，来做计算的，对，这种连接就更多了，有时的时 14 次方这么多

229
00:23:05.370 --> 00:23:15.850
说话人 3: 那么我们想想一下，假设有一天有一个能力能够把所有的这些信息全都上传，那么从理论上来说这是可能的

230
00:23:16.230 --> 00:23:20.270
说话人 3: 但是从现实当中来说，我们还看不到这一天

231
00:23:20.710 --> 00:23:21.470
说话人 1: 噢，还看不到

232
00:23:21.550 --> 00:23:32.750
说话人 1: 对，那么现在我不明白，就是说现在就人机互联，嗯，最关键的地方就是你这个机器和这个生物的神经，他这怎么就连我就有点想象不出来

233
00:23:32.830 --> 00:23:35.510
说话人 1: 或者就能读取我脑子里的信息

234
00:23:35.870 --> 00:23:36.190
说话人 1: 对

235
00:23:36.190 --> 00:23:41.510
说话人 3: 现在读取这个事儿在大脑神经学里面已经可以做到了

236
00:23:41.510 --> 00:23:51.610
说话人 3: 比方说之前他们是拿一个探针，嗯，探到这个连接里面去，然后就把你这个连接的强弱给读出来

237
00:23:51.650 --> 00:24:03.220
说话人 3: 但是在过去的这个做法就破坏了这个连接，也就是说这个假设我，我来做你的实验，那么你就变得越来越傻了，哈哈哈，我们不希望看到这个事儿

238
00:24:03.260 --> 00:24:09.620
说话人 3: 对，所以今天他们就发明了一种用激光去读，这样就无损于这个

239
00:24:09.620 --> 00:24:09.660
说话人 3: 你

240
00:24:09.660 --> 00:24:10.740
说话人 2: 读出来是什么呢

241
00:24:10.740 --> 00:24:12.220
说话人 2: 能复原他原来想什么

242
00:24:12.220 --> 00:24:13.100
说话人 3: 吗

243
00:24:13.140 --> 00:24:19.990
说话人 3: 没有，他读出来是一个单一的一个beat，就是一和 0 这样的一个观念，那他

244
00:24:20.070 --> 00:24:21.830
说话人 1: 不是想法，在他读出来不

245
00:24:21.830 --> 00:24:23.510
说话人 3: 还行，完全不是想法

246
00:24:23.790 --> 00:24:31.530
说话人 3: 所以他读出这么一回来，你想和 10 的 14 次方这么多维，那是千差万别的

247
00:24:31.810 --> 00:24:32.210
说话人 3: 窦文涛

248
00:24:32.210 --> 00:24:35.170
说话人 2: 脑子里读出来可能跟毛泽东脑子里读出来差不多

249
00:24:35.490 --> 00:24:35.570
说话人 2: 不

250
00:24:35.690 --> 00:24:44.650
说话人 1: 那你说现在所谓的像有些这个人机互联，最简单的就是那个残疾人人际化，怎么说意念就能驱动这个假肢了

251
00:24:44.890 --> 00:24:45.250
说话人 1: 对

252
00:24:45.250 --> 00:24:54.490
说话人 3: 它是有很多我们人在想东西的时候，我们的脑电波会有变化，嗯，然后如果我们带一个特殊的装置，我们会把这个脑电波

253
00:24:54.490 --> 00:24:55.850
说话人 2: 的变化的手抬起来

254
00:24:55.850 --> 00:24:58.290
说话人 3: 对，简单的变化给它读出来

255
00:24:58.290 --> 00:25:16.950
说话人 3: 嗯，那么这样的话，我们在想东西的时候，只要我们去读那个部位的变化，如果很敏感的话，我们就可以去控制机器手了，但是这种脑电波的读取现在是非常非常的不准，里面有很多噪音

256
00:25:17.430 --> 00:25:17.870
说话人 3: 对

257
00:25:17.950 --> 00:25:27.150
说话人 1: 那要是聊天就你比如说Siri，唉，你你，你跟 Siri 我都能感觉到 Siri 再变得聪明一点，但还是比较脑残

258
00:25:27.190 --> 00:25:32.630
说话人 1: 就是你你，你觉得你跟机这个智能聊天他能聊到一个什么程度

259
00:25:32.920 --> 00:25:40.910
说话人 3: 现在我们熟悉的有Siri，有小冰、小度什么这些，那么大部分都是这种闲聊

260
00:25:41.150 --> 00:25:54.530
说话人 3: 所谓闲聊就是他拿了很多很多微博，还有这种网络的这种数据来做训练，然后他就会学会一个网络语言，所以他只能闲扯，他不能为你

261
00:25:54.570 --> 00:25:57.500
说话人 2: 他有自任性的，可以附近有什么电影院

262
00:25:57.780 --> 00:26:00.180
说话人 3: 对知识性的他就一问一答

263
00:26:00.380 --> 00:26:01.860
说话人 3: 嗯，这种还比较靠谱

264
00:26:01.860 --> 00:26:03.860
说话人 1: 人格性没有形成

265
00:26:04.020 --> 00:26:07.060
说话人 3: 但是在对人格或者甚至在
