
1
00:00:12.140 --> 00:00:17.380
说话人 1: 锵锵三人行，这，吴军老师，咱们是这个鸡年头一回见面

2
00:00:17.380 --> 00:00:24.180
说话人 1: 对对对对，当然今天我特别开心的是见到慕名已久的这个清华美女

3
00:00:24.460 --> 00:00:26.660
说话人 1: 周老师好，警方老师，吴老师好

4
00:00:26.660 --> 00:00:32.340
说话人 1: 对，这个警方老师，首先得祝贺你这个科幻小说获得雨果奖

5
00:00:32.380 --> 00:00:34.340
说话人 1: 谢谢，但是你觉得我这祝贺有点晚吗

6
00:00:35.090 --> 00:00:37.770
说话人 2: 我们也是我获奖之后第一次见，所以不了

7
00:00:37.770 --> 00:00:39.650
说话人 1: 哈哈哈，太聪明了，会说话

8
00:00:39.690 --> 00:00:49.400
说话人 1: 对，你刚得奖的时候我们就请，我们请不来，所以说我这个祝贺也迟到今天，而且你看我今天给你们搭配的，你们俩有缘

9
00:00:49.560 --> 00:00:50.160
说话人 1: 嗯，对吧

10
00:00:50.160 --> 00:00:54.160
说话人 1: 太有缘了，你首先都跟清华有关系，对吧

11
00:00:54.160 --> 00:00:55.560
说话人 1: 对，咱们这个警方

12
00:00:55.560 --> 00:00:58.480
说话人 1: 唉呦，你又是研究物理学的

13
00:00:58.520 --> 00:00:59.680
说话人 1: 是硕士

14
00:00:59.720 --> 00:01:07.070
说话人 1: 嗯，然后这个经济金融方面还是博士，现在这个国务院下边的一个智库里工作是吧

15
00:01:07.150 --> 00:01:11.470
说话人 1: 他研究经济，所以你说这是才女，现在让我们男的没法混了都

16
00:01:12.310 --> 00:01:20.340
说话人 2: 哈哈，其实这个研究员里面的女生现在越来越多了，就是女生还做研究员挺合适

17
00:01:20.340 --> 00:01:22.580
说话人 1: 的，要不咱谈谈未来的女权问题

18
00:01:22.580 --> 00:01:29.980
说话人 1: 哈哈哈，你觉得，唉，这个未来，这个你认为女性会全面的碾压男性吗

19
00:01:30.400 --> 00:01:36.000
说话人 2: 碾压说不上，就是各司其职，就是女适合女性的工作其实会越来越多

20
00:01:37.240 --> 00:01:45.100
说话人 1: 甚至像科幻小说，过去咱们觉得是男性的这个天下，但是你的那个科幻被归类为是软科幻

21
00:01:45.500 --> 00:01:45.860
说话人 1: 对

22
00:01:45.900 --> 00:01:48.220
说话人 3: 嗯嗯，我倒觉得像政治小说

23
00:01:48.660 --> 00:01:49.420
说话人 1: 没错了

24
00:01:49.780 --> 00:01:54.580
说话人 1: 而且我觉得你们俩还有一点可以作为咱们今天的这个话题

25
00:01:54.700 --> 00:02:03.370
说话人 1: 嗯，就是警方写的这个北京折叠，我在多个地方这个论坛上我都引用，因为我觉得这是一个最好的

26
00:02:03.370 --> 00:02:03.730
说话人 1: 是吧

27
00:02:03.930 --> 00:02:11.300
说话人 1: 可以讽刺一下社会现实的，就是说北京分成三个世界，嗯，三种人

28
00:02:11.340 --> 00:02:12.300
说话人 1: 为什么我说这个

29
00:02:12.300 --> 00:02:15.060
说话人 1: 吴军老师也有一句话把我给惊着了

30
00:02:15.060 --> 00:02:22.140
说话人 1: 对，说是这个，去年尾上有一个叫万物互联大会，对，您有一个演讲

31
00:02:22.140 --> 00:02:27.120
说话人 1: 对对，唉，当时吴军老师对未来的预言就是说未来的时代

32
00:02:27.240 --> 00:02:33.840
说话人 1: 嗯，只有 2% 的人能脱颖而出， 98% 的人都是废物点心

33
00:02:34.160 --> 00:02:37.520
说话人 3: 倒也不是，废物点心这个数据不是这么算出来的

34
00:02:38.640 --> 00:02:39.760
说话人 1: 那您这话是怎么

35
00:02:39.760 --> 00:02:39.840
说话人 3: 说

36
00:02:39.840 --> 00:02:43.120
说话人 3: 是这样子啊，就是说当时不是有一个占领华尔街嘛

37
00:02:43.160 --> 00:02:48.040
说话人 3: 对，那百分之有些人就说我们是 98% 的，那我们反对谁呢

38
00:02:48.040 --> 00:03:15.030
说话人 3: 就反对了 2% 的，所以他们把这个人分成分这么两个阵营，少数的得益于我们说得益于全球化，得益于科技进步等等这些人，那么还有剩下来的人这样子，所以是这么没有绝对说一定是 1% 还是 2% 或者5%，但是总体来讲就是极少数的人会受益，那比较多的人可能会就跟他们的差距会拉得很大

39
00:03:15.150 --> 00:03:15.350
说话人 3: 这

40
00:03:15.350 --> 00:03:17.230
说话人 1: 似乎也是你在小说里看到的

41
00:03:17.230 --> 00:03:18.270
说话人 2: 未来

42
00:03:18.390 --> 00:03:33.480
说话人 2: 对，我在北京折叠里面是写到说那个时候可能大部分人是失业的，其实没有到 2% 98% 那个状态，但是会写到说有一部分人他们的工作被机器人取代了，他们做不了别的，所以就是一个很大的社会问题

43
00:03:33.720 --> 00:03:46.280
说话人 2: 但是在现实中其实我没有这么悲观，我会觉得未来的只是形态，社会上会和现在不一样，但并不意味着有很多的那样的人会失业，因为有很多新的工作会诞生

44
00:03:46.400 --> 00:03:47.400
说话人 1: 比如说什么工作

45
00:03:48.320 --> 00:03:55.520
说话人 2: 什么都可以，就是我们现在定义的很多的这种职业方向已经和 50 年前非常不一样了

46
00:03:55.720 --> 00:04:02.040
说话人 2: 这个我们说的那种被取代就是像机器，它会很容易做的，像生产，它把工人取代了

47
00:04:02.200 --> 00:04:15.070
说话人 2: 但是有与此同时也有很多其他的工作是就是新出来的，就比如说我们今天大家都会愿意为了看看大家聊天来付钱聊天，现在这不就是一个工作吗

48
00:04:15.150 --> 00:04:24.990
说话人 2: 像您聊天聊的好的，这个就是一个职业，那未来的话可能有很多人他就专门负责聊天，然后聊 500 块钱天，这个也本身就可以成为职业嘛

49
00:04:24.990 --> 00:04:26.910
说话人 1: 那我们是属于 2% 啊

50
00:04:27.000 --> 00:04:34.630
说话人 3: 哈哈哈，但是这个少，我觉得新的工作从数量上来讲就是说很难弥补旧的工作的损失

51
00:04:35.430 --> 00:05:14.830
说话人 3: 那你如果看两个数据，一个就是说美国数据，说奥巴马为什么那个政策，大家那个对它的反弹，或者是说那种负面的看法很大，就是说一方面它显得失业率在不断的下降，但是美国还有一个数据就是就业率，这两加起来不是100%，就是说这个就业人口处于总人口，他当政的这八连是美国历史上，就是过去 30 年历史上最低的八连，因为大家找不着工作，不找了，这个就业利率大概也就60%，大概美国就是，然后有很多年轻的这个人，大概有 20% 的年轻人是找不着工作的，而且年轻时候就找不着，一辈子找不着

52
00:05:15.270 --> 00:05:51.280
说话人 1: 呦，我最近就是思想上发生一个更新，说起来因为我总是马后跑就后之后句，我们这文科生现在在你们这个理科精英面前，那简直就没法活下去，所以，但是我也觉得好像是一夜之间，大概就是这几个月来我收到的种种这个资讯哪让我一下子意识到可能我们站在一个新时代的门槛上开始，对，就是因为在我的身边，突然之间这个机器人 AI 人工智能，包括我们请来的嘉宾，那坐你这个位置

53
00:05:51.280 --> 00:06:10.410
说话人 1: 聂伟平，前一日子，哇家伙这 Alphago 的这个升级，对对对，把这聂齐上 60 盘全赢，突然一下子你就觉得这个时代还有一点就是这个，我跟吴京老师最近都注意到一本书，就以色列那个学者，对对对，未来简史，对对吧

54
00:06:10.490 --> 00:06:21.370
说话人 1: 你看他这个让我们一下子就意识到好像一个新的时代，嗯，甚至说数据和算法这个词比人还重要了

55
00:06:21.860 --> 00:06:26.060
说话人 3: 就是实际上我们现在某种程度上很多人的生活已经受这个影响

56
00:06:26.060 --> 00:06:41.620
说话人 3: 就是我在我这个智能时代也讲这个，就比如说你如果天天在淘宝上泡，在这上面买东西，那个接受他给你的推荐等等，你实际上是被阿里巴巴的数据和算法在控制着

57
00:06:42.280 --> 00:06:52.920
说话人 1: 你看马云那模样就像个控制社，哈哈哈，而且我就觉得你像咱们这个受党教育多年，我发现这个马克思主义真的是很难丢下

58
00:06:52.960 --> 00:06:54.320
说话人 2: 共产主义要实现了

59
00:06:54.320 --> 00:06:54.880
说话人 2: 是这样

60
00:06:55.000 --> 00:07:17.060
说话人 1: 的，你就包括这个未来简史里讲的这个，对，你说包括你这个北京折叠里面其实就是个阶级问题，那阶级问题在这个新的智能时代或者大数据时代，你比如说我在这个书里，我举个例子来讲，你的小说里讲的是就说这些草根阶层将来的这个机器智慧

61
00:07:17.300 --> 00:07:25.380
说话人 1: 唉，就是纯粹我觉得是慈善事业才让你们扫扫大街，要不然把你们这活剥削，你都没有剥削的价值，太惨了

62
00:07:25.920 --> 00:07:34.760
说话人 1: 但是我在他这本书里，他比如说他觉得科技改变人类，那么现在已经到了一个什么境界

63
00:07:34.760 --> 00:07:39.150
说话人 1: 就是说下一个时代可能要探索人类长生不死

64
00:07:39.190 --> 00:07:43.550
说话人 1: 嗯，您在谷歌待过，您知道这个库兹韦尔吗

65
00:07:43.590 --> 00:07:48.710
说话人 3: 我知道，我知道它是一个半人半神的，就是那它不是一个主流的科学家

66
00:07:48.940 --> 00:07:50.050
说话人 3: 他说的靠谱吗

67
00:07:50.090 --> 00:07:50.690
说话人 3: 不太靠谱

68
00:07:50.690 --> 00:07:51.330
说话人 3: 我觉得不太

69
00:07:51.330 --> 00:07:55.490
说话人 1: 靠谱，他说他要活到 2045 年，他说 2045 年人类对

70
00:07:55.490 --> 00:07:58.330
说话人 3: 长生，但是后来又改成 2039 年，好像听说

71
00:07:58.410 --> 00:07:59.530
说话人 3: 噢，他还提早一年

72
00:07:59.530 --> 00:08:01.530
说话人 3: 好，这不是20452039，差好几年

73
00:08:01.650 --> 00:08:04.610
说话人 1: 这个未来简史里说是就是

74
00:08:04.610 --> 00:08:06.530
说话人 3: 2033 年，好像是一个

75
00:08:06.530 --> 00:08:08.170
说话人 1: 大概 2050 年还是什么的

76
00:08:08.210 --> 00:08:08.730
说话人 1: 有一个

77
00:08:08.730 --> 00:08:11.530
说话人 3: 我反正我记不住，他说了好几个年代，反正

78
00:08:11.530 --> 00:08:31.470
说话人 1: 是你比如说我现在还注意到他很多种说法，咱这可能是我不知道是不是科学的，比如说现在有一个科研方向是发现那有一种药，嗯，很有意思，好像叫二甲双胍，那个字念二甲双菇什么的，因为就是说就是糖尿病那个降糖的药

79
00:08:31.470 --> 00:08:34.750
说话人 1: 对，现在有些人发现这个药很神奇

80
00:08:34.830 --> 00:08:42.130
说话人 1: 嗯，说这个东西好像将来也是能够解决人类衰老的一个研究方向，您有听说吗

81
00:08:42.250 --> 00:08:42.610
说话人 1: 就是

82
00:08:42.610 --> 00:08:59.510
说话人 2: 其实就是这个人类的这个细胞衰亡，这个问题是没有那么简单，到了说某一种分子或者某一个基因就能是他的问题，因为包括这个细胞死亡基因，也挺多年前就有人在说这个事情

83
00:08:59.750 --> 00:09:03.830
说话人 2: 嗯，然后但是那个这个总的来讲它是一个大的系统工程

84
00:09:03.990 --> 00:09:10.070
说话人 2: 但我不怀疑说未来，实际上这个各靠各种更新，这个寿命会增长

85
00:09:10.230 --> 00:09:11.990
说话人 2: 我觉得这个其实未来很容易

86
00:09:11.990 --> 00:09:12.310
说话人 1: 是一个

87
00:09:12.310 --> 00:09:16.190
说话人 1: 对，你看他说几个方向，这是一个是生物医学，是一个方向

88
00:09:16.440 --> 00:09:19.800
说话人 1: 再有一个是这种人机互联是一个方向

89
00:09:19.800 --> 00:09:26.240
说话人 1: 嗯，甚至还有那个更玄的，我记得您原来也提过人的意识将来能不能存在一个芯片里

90
00:09:26.520 --> 00:09:58.460
说话人 2: 对，这个昨天我们对，也和一些朋友在了解这个事情，实际上这个人的这个意识，它跟计算机的那个计算机存储是很不一样的，对人的这个意识，它并不是在电脑里面，就在人脑里面像一个静态图片就放在那，你把你的意识存在那个电脑里面，就像静态图片一样等着去访问人，不是人所谓的记忆意识等等，它其实是一个动态的一个过程，就是你的意识就是你这个脑细胞的一组，你教他放电方式吧，就是

91
00:09:58.460 --> 00:09:59.580
说话人 1: 电化学，对

92
00:09:59.580 --> 00:10:00.180
说话人 2: 电化学

93
00:10:00.180 --> 00:10:21.990
说话人 2: 然后它是一个过程，就是你你整个的这个大脑，并不是说只是大脑，它和你身体完全相关的，就是你身上的每一个肌肤，你的每一个手指，你的眼睛、你的耳朵都是你大脑的一个组成部分，它这个一个信号进来了，要经过整个这一个过程的处理，到大脑那边再处理再返回

94
00:10:22.150 --> 00:11:11.750
说话人 2: 所以你如果光把这个东西传到一些静态数据传到电脑上，你剩下的一切全都抛弃掉的话，你这个过程其实就没法持续了，我是这么觉得，当然了，你可以说未来全都改成模拟的，然后你在电脑上也模拟的你的手的手臂的输入，模拟你自己的这个那个眼睛看到的，模拟耳朵听到的，然后还得模拟出身你身上的所有的化学信号，因为否则的话你因为人的很多意识是和化学信号是有关系的，你的这个多巴胺的分泌器，甲肾上腺素的分泌，对所有的这些化学信号都会影响到你的思维，那你要每一个分子都得拿计算机信号去模拟，其实我个人感觉这个是一个不太可能，说真的是模拟出来你的这个

95
00:11:11.750 --> 00:11:57.670
说话人 3: 另外一个可能不太必要，我觉得，对，而且我这生死我是这么看的了，因为那个是我父亲过世的比较早，所以我就觉得我看的还比较透，有生必有死，追求这个长生没有任何意义

96
00:11:58.320 --> 00:12:10.680
说话人 3: 那个，而且人的就是说这我虽然不是基督教徒了，但是我一直也感觉说这个世界上是有一种敏敏的力量，在它背后有一种冥冥来来来控制着

97
00:12:10.680 --> 00:12:22.280
说话人 3: 比如说，唉，还有一本书叫自私的基因，自私的基因，对对对对，这是很有名的一个分子学这个进化论的一本书，他就讲说我们实际上都是 DNA 的奴隶

98
00:12:22.320 --> 00:12:26.720
说话人 3: 对，我们这个身体之所以存在就是为了一个 DNA 的传承

99
00:12:26.760 --> 00:12:35.600
说话人 3: 嗯，那么一个衰老的机体死亡掉，使得我们这个 DNA 能够传承下去，这就本身它就完成了这个

100
00:12:35.600 --> 00:12:36.000
说话人 2: 任务

101
00:12:36.040 --> 00:12:48.490
说话人 2: 但是其实如果按照他这个理论的话，那这个人就更应该不断的更新自己了，因为自己的儿女只跟自己想 50% 的DNA，但是自己跟自己是享有 100% 的共同的DNA

102
00:12:48.970 --> 00:12:54.050
说话人 2: 所以如果一个 DNA 他来做选择的话，肯定是不断更新自己，对他这个

103
00:12:54.050 --> 00:12:59.890
说话人 3: 样子，这个 DNA 他这样，这不是说你一个 DNA 是这一种DNA，整个的就是

104
00:12:59.890 --> 00:13:01.530
说话人 2: 你把这个人类物种

105
00:13:01.530 --> 00:13:03.010
说话人 3: 当成一个物种

106
00:13:03.130 --> 00:13:14.670
说话人 3: 然后再有那回我跟 KK 在聊这件事，那凯文凯利在中国也很利，也很红他，他就说这个，他说你看世界上只有一种细胞是不死的，就是癌细胞，是吗

107
00:13:14.670 --> 00:13:19.890
说话人 3: 对，癌细胞是可以不死的，但是癌细就导致就是我们机体死掉

108
00:13:19.930 --> 00:13:26.490
说话人 3: 对，那么所以也是，就是说如果我们这个死人，我们的社会就死掉了，我们这整个人类可能

109
00:13:26.490 --> 00:13:26.610
说话人 1: 就死

110
00:13:26.730 --> 00:13:35.520
说话人 1: 但是科学家，所以您是，您能站在一个人文的高度上觉得这个生死是，对吧

111
00:13:35.520 --> 00:13:37.320
说话人 1: 对，为什么非要追求不死

112
00:13:37.400 --> 00:13:43.610
说话人 1: 对，可是智人，他可我不管这个，他只要一发现有这个可能性

113
00:13:43.650 --> 00:13:49.370
说话人 1: 嗯，我觉得他有一个道理，就是说比方说现在说这个基因检测

114
00:13:49.370 --> 00:13:56.730
说话人 1: 对，那么如果发现这个胎儿有什么问题，嗯，可以选择要或者不要，你比如试管婴儿，你就有个挑选

115
00:13:57.060 --> 00:14:03.420
说话人 1: 对，那说你掌握了这个技术，接下来你甚至有可能想，那我要修改一下呢

116
00:14:03.460 --> 00:14:03.860
说话人 1: 对，就

117
00:14:03.860 --> 00:14:06.820
说话人 3: 现在很容易想到基因编辑，就是张峰他们搞那个

118
00:14:06.820 --> 00:14:11.660
说话人 1: 对，那你修改一下就会出现这个超好遗传的这样的人

119
00:14:11.740 --> 00:14:21.870
说话人 3: 嗯，不一定，不一定，因为是两个，就是说一个原因是说这个它的好多基因不是一个基因在控制，是多组基因

120
00:14:22.330 --> 00:14:28.010
说话人 3: 比如说举个最简单的例子，就是说我们色盲，这是一个基因在控制，你出现色盲你知道是哪个基因

121
00:14:28.050 --> 00:14:29.570
说话人 3: 你把如果真修复好就好了

122
00:14:29.890 --> 00:14:35.910
说话人 3: 心脏病是好多基因控制，你修了那个可能把另外一个更弄得更坏是有可能的

123
00:14:36.630 --> 00:14:43.030
说话人 3: 那么实际上我们我前置还投过一家公司叫做人类长寿，这公司就是追求人类长寿，这不您

124
00:14:43.030 --> 00:14:44.430
说话人 1: 也投嘛，你，对对对，不是

125
00:14:44.430 --> 00:14:59.680
说话人 3: 我投这公司就是说他研究抗癌致癌，他那个这个创始人叫快格温特，是最早搞人类基因组计划的，这个负责人得过美国总统奖，克林顿当时给他授的这个奖就是国家科学奖

126
00:15:00.020 --> 00:15:17.840
说话人 3: 他那天给我讲一个，他说根据他们那研究，他有5万个人完整的基因，就全图补基因，他们搜集了就说为什么得癌症，我们说污染哈，各种原因哈，食物什么，他说 98% 的不是 92 的原因

127
00:15:17.960 --> 00:15:24.560
说话人 3: 嗯，说白了就是你太老了，没别的污染，所有这些东西贡献了 8% 的这个原因

128
00:15:24.880 --> 00:15:41.680
说话人 3: 他说这个人的基因当时就是老了以后里面就坏了，就像比如一堵一个水坝，千疮百孔，你如果那个就是修复好一个，你就相当于堵了一个小孔，你可能坏了1万个

129
00:15:42.160 --> 00:16:09.760
说话人 3: 实际上从某种角度来讲不值得，这个水洼也不值得修了，修了那个人类现在其实基本上他们比较准确推算自然寿命在 115 岁，嗯，个别人会长寿，就偶尔有记录接近 120 岁，但是过去已经很多年了，大概就是每年的这个最长寿的记录，现在还最近很多年都没有超过这115

130
00:16:09.840 --> 00:16:10.280
说话人 3: 嗯，那您

131
00:16:10.280 --> 00:16:13.160
说话人 2: 投的这公司他们是做什么叫长寿公司

132
00:16:13.160 --> 00:16:19.880
说话人 3: 人类长寿它是这样子，它就是说它是一个其实是通过基因检测，然后帮助生物制药

133
00:16:20.410 --> 00:16:22.610
说话人 3: 那么比如它有好几个应用

134
00:16:22.610 --> 00:16:32.410
说话人 3: 第一个应用就是说现在很多抗癌药，就是比如对张三管用，对李四不管用，那么他们最大的一个客户是基因泰克，就是做了一个抗癌药的那个公司

135
00:16:32.840 --> 00:16:39.560
说话人 3: 那么他就要搞清楚为什么这个药对有些人管用，对另外一些人不管用，他们在基因上有什么差异

136
00:16:39.840 --> 00:17:08.210
说话人 3: 这是一个，再有一个他提供一个服务，就是说大概差不多你掏1万美元给他，但是他成本没这么多，他把你的基因全图谱的做一个检测完了的话，你未来有可能得什么病，他不断的给你跟踪管理，就是这样的，对，有了什么新的治疗方法，对你这个病或者说有些防治的方法，他及时通知你，他就是你就是检完测完他给你送礼一个iPad，这以后他每天这些东西他就跟这个 iPad 就随着你走

137
00:17:08.250 --> 00:17:08.930
说话人 3: 他是这样

138
00:17:09.050 --> 00:17:29.140
说话人 1: 你说我看这本书就从这个点上，我为什么我说我就想起你那个北京折叠，就是它预示着未来的一个马克思主义的这个可能性，就是说长生不死这个技术，嗯，最早那肯定是有钱的人，对，他能够掌握，实际现在就是有钱的人就能有更好的医疗服务，这是没有问题的

139
00:17:29.360 --> 00:17:39.190
说话人 1: 但是这个科技几何级数的拉大距离之后，将来咱不说不死，您能活 200 岁，我们这草根结草是吧

140
00:17:39.230 --> 00:17:40.670
说话人 1: 七八十岁就完了

141
00:17:40.930 --> 00:17:46.570
说话人 1: 我，唉，过去说你马云有点钱，你王健林比我有点钱，这我也就忍了，对吧

142
00:17:46.610 --> 00:17:49.450
说话人 1: 对，刚你不死了，我

143
00:17:49.530 --> 00:17:50.770
说话人 3: 这不会不死，那

144
00:17:50.770 --> 00:17:52.170
说话人 1: 人民就革命了吧

145
00:17:52.170 --> 00:17:52.330
说话人 1: 我

146
00:17:52.330 --> 00:18:01.830
说话人 3: 觉得这是一个自然规律，就是说如果我们相信有一个超出我们人类不叫，嗯，上帝叫什么

147
00:18:02.350 --> 00:18:13.660
说话人 3: 超级的力量，就是说它的存在的话，它制造了我们整个宇宙的这些规律，你实际上人很难超脱这个控制在很多地方上

148
00:18:13.660 --> 00:18:19.380
说话人 3: 我跟大家讲，就你，你就是说有人说，唉，你，我们说叫知天命，什么叫知天命

149
00:18:19.380 --> 00:18:24.520
说话人 3: 就是说你如果相信，说人的本事不是万能的，这某种成员就是知天命

150
00:18:25.160 --> 00:18:26.880
说话人 1: 哎呦，您这科学家讲天命

151
00:18:27.120 --> 00:18:43.460
说话人 3: 不是确实这样，比如我老跟人讲做投资的，讲这么一件事，我说你们要知道所有的市场，甭管是做风险投资也好，还是做那二级市场，这股票投资也好，谁都不是老大，政府都不是老大，老大是道的，是上帝

152
00:18:43.980 --> 00:18:55.620
说话人 3: 就是说任何一个人你做这个投资以前，你对告的要有一封敬畏，你不要觉得说我有多少钱，我能够操纵市场，什么什么这些都是做不到的

153
00:18:55.920 --> 00:19:03.990
说话人 3: 最终那个当你们做的太离谱的时候，就像我们说金融危机、次贷危机是美国，是告的会惩罚里

154
00:19:04.150 --> 00:19:12.510
说话人 3: 所以这个我觉得就是说从我的对世界认知来讲，有一种灵敏的力量在这儿

155
00:19:12.670 --> 00:19:36.460
说话人 2: 就是这个，其实可能是说统计学，如果我们把所有人类当成一个统计学的话，从统计的角度来讲可能还是会有一某种稳定性，就是一个按照统计规律，嗯，应该如何，你所以一个人他做很多事，他这长期看可能是一个规律，然后可能整个社会它稳定的会平均在某个规律上

156
00:19:36.580 --> 00:19:42.300
说话人 2: 但是是否就是能够有人就始终处于这个统计之上

157
00:19:42.300 --> 00:19:46.730
说话人 2: 就是就像抛硬币一样，多少次都在这个统计

158
00:19:46.890 --> 00:19:47.290
说话人 1: 之上

159
00:19:47.290 --> 00:20:04.160
说话人 1: 您看您也是现在研究经济，你觉得这种贫富的矛盾，贫富差阶层的这个固化和拉大结合上这个科技革命，你预测在未来是进一步拉大这个鸿沟，还是有可能弥合这个

160
00:20:04.160 --> 00:20:04.560
说话人 2: 鸿沟

161
00:20:04.640 --> 00:20:11.640
说话人 2: 就是实际上那个斯蒂芬平克有一个心智探奇，那本书里面写到一个最根本的背陋，我觉得那个是最关键的

162
00:20:11.800 --> 00:20:21.700
说话人 2: 他说人类社会不可能就是永远保持就三个状态，同时一个是公正，嗯，一个是自由，一个是平等，嗯，为什么呢

163
00:20:21.740 --> 00:20:27.020
说话人 2: 因为如果是公正就意味着多劳多得，然后谁干得好谁就挣得多，这叫公正，对吧

164
00:20:27.260 --> 00:20:27.780
说话人 2: 然后呢

165
00:20:27.860 --> 00:20:28.460
说话人 2: 自由呢

166
00:20:28.460 --> 00:20:39.580
说话人 2: 就是你得的东西你可以自由分配，想干什么干什么，那么所有人的人性都会把自己得的东西给儿子，然后给孩子，然后这样的话就达不到平等了

167
00:20:39.700 --> 00:20:47.540
说话人 2: 就意味着说多劳多得的人，他的孩子先天的就多，然后积累下去的话，这个确实是会

168
00:20:47.540 --> 00:21:08.490
说话人 2: 所以实际上如果你看那个长期历史的话，那个为什么人经常我们合久必分，分久必合，我们一段时期繁荣，一段时期乱，就是有的时候这种张力，这种积累，某些人积累的太好了，另外一些人什么都没有，这种状态到了一定的程度，矛盾太大了，然后就合并

169
00:21:08.490 --> 00:21:09.050
说话人 3: 了

170
00:21:09.250 --> 00:21:13.650
说话人 2: 让社会就重新对打破，重新洗牌开始

171
00:21:13.850 --> 00:21:17.170
说话人 2: 然后未来的话，这个科技也是有可能的

172
00:21:17.330 --> 00:21:35.490
说话人 2: 因为先不说这些人不死，他们如果能够基因修改的话，那么其实可能就是在某些方面，像您说的改的更优化一点是有可能的，就是会积累到超出一般人的一些，这个就是先天优势，我觉得是有的

173
00:21:35.690 --> 00:21:48.710
说话人 2: 所以这个但是如果你要说这个冥冥中有某种规律使得人类社会回归到平衡的话，那可能就是还是会社会不稳定啊，这个重新洗牌

174
00:21:48.710 --> 00:22:20.630
说话人 1: 等等，听上去希望都不是太大，对枪三人行广告之后见，当然刚才吴军老师您讲这个guard，明明之上有个guard，我现在发现你看我通过看这个未来简史这个书，包括您的智能革命，我觉得这个尬的是不是也可以除昧了

175
00:22:20.630 --> 00:22:24.000
说话人 1: 就是他，他这个上所谓这个上帝是什么

176
00:22:24.240 --> 00:22:39.520
说话人 1: 比如说现在这有的人他就提出，嗯，就是您讲的万物联网，嗯，最后这个数据就整个人类社会从一个个体到一个国家到一个地球，嗯，无外乎就是超级复杂的一种算法

177
00:22:40.160 --> 00:22:44.950
说话人 1: 那么这个尬的指不指的是不是这个全数据的这个处理系统

178
00:22:45.310 --> 00:23:17.980
说话人 1: 那么这个全数据的处理系统你看咱们举个例子来讲，我又想讲马克思主义，马克思其实我觉得他完成了一个第一阶段，对，就是说人的异化，嗯，他就发现你看像卓别林那个生产线上的一个工人，他就会拧螺丝，他就会拧，他不知道他拧螺丝跟他最后产出这个东西之间是什么关系，但人就变成一个工具，对，甚至是最后产出的那个利润决定了这个拧螺丝的这个人，对，对，还有没有必要存在，对，对吧

179
00:23:17.980 --> 00:23:18.060
说话人 1: 对

180
00:23:18.180 --> 00:23:29.040
说话人 1: 那么你像未来简史这本书，它的意思就是说将来这个都是这个算法，比如说您也讲过，嗯，将来一个城市可能就是一个超级电脑在控制，对吧

181
00:23:29.320 --> 00:24:00.280
说话人 1: 那么这个规模我们要无远福界放大的话，有一个忧心，就是说会不会有一天这个超级算法认为你这个人也是其中维持我这个系统的工具和环节之一而已，那么我为了更有效率的运作把你灭了也没有什么不可以，或者说你要说这个嘎子就是这个冥冥之上的这个宿命的话，嗯，那无数物种的这个灭绝也都是这个超级算法的选择，对吧

182
00:24:00.360 --> 00:24:02.320
说话人 1: 你不能适应环境，你可以

183
00:24:03.280 --> 00:24:11.080
说话人 3: 这个走了，那个自然选择，他就是讲的这么残酷，就像个剪刀似的，看你这个枝子不顺眼就给剪了，你这物种就灭绝了

184
00:24:11.240 --> 00:24:12.640
说话人 3: 对，这是过去的说法

185
00:24:12.760 --> 00:24:16.800
说话人 2: 但是这里面有一个问题，就在于说目的到底是什么

186
00:24:16.920 --> 00:24:31.460
说话人 2: 比如说我们现在人说我们想要剪头发是为了美观，我们有一个目标，我们有一个价值观是美观，然后我们想要做一些身体上面的修改，我们知道这个是一个病，我们要给它去除

187
00:24:31.740 --> 00:24:36.780
说话人 2: 如果你要想到说现在有这么一个超级智能，它的目标是什么

188
00:24:36.900 --> 00:24:45.170
说话人 2: 就是如果它已经全球联网成一个超级智能，他的目标到底是说我要更好的利用这个星球吗

189
00:24:45.330 --> 00:24:56.770
说话人 2: 还是我就是因为对于他来讲没有说我要弄得更漂亮一些，或者说他是到底是想要保留更多的人，对他来讲是好，就是让人繁衍，还是他也不需要人

190
00:24:57.040 --> 00:25:01.560
说话人 2: 他不需要人的话，那对于他来讲什么是他的目的

191
00:25:01.560 --> 00:25:04.840
说话人 2: 所以我们人为什么有这么多的这么强的目的

192
00:25:04.960 --> 00:25:10.080
说话人 2: 因为我们作为一个生物，我们有这个生存的这个你比如说是最基本的这些

193
00:25:10.080 --> 00:25:16.190
说话人 1: 需求，你比如举个例子，将来咱就说这个超级智能共产主义实现了，嗯，对吧

194
00:25:16.710 --> 00:25:24.910
说话人 1: 那么按照你北京折叠里的说法，那这个智能，也许，比如说他感觉到实际上这个人干的活机器都能代替

195
00:25:24.910 --> 00:25:27.110
说话人 1: 对，那么所谓的草根阶层，是吧

196
00:25:27.270 --> 00:25:30.680
说话人 1: 也不是让你们扫大街去，你们都到海滩玩去吧

197
00:25:30.680 --> 00:25:33.400
说话人 1: 嗯，对，就把你们都玩去吧，对吧

198
00:25:33.400 --> 00:25:36.960
说话人 1: 不用你们了，对的，那你说这对人类是福还是

199
00:25:37.520 --> 00:25:37.560
说话人 2: 祸

200
00:25:37.560 --> 00:25:44.200
说话人 2: 这个在那其实有一个动画片，就是那个瓦里那个动画片，对对对，然后大家都在那吃薯片，看着笑一件事

201
00:25:44.200 --> 00:25:55.010
说话人 2: 对对对对对对，这这个其实是可能更有，就是其实是更有前景，不是，就是更有可能性的一种，你说不上它是好还是坏，但是它其实是一个Passport

202
00:25:55.410 --> 00:26:10.330
说话人 2: 就是说现在不是也有很多人提那个就是共同收入，然后你有了，每给每个人都发那个全都平等的收入，你们也不需要工作了，基本的对工，基本的收入，然后基本收入你就拿着这个钱去娱乐吧

203
00:26:10.330 --> 00:26:11.810
说话人 2: 然后这个是有可能会

204
00:26:11.810 --> 00:26:15.410
说话人 1: 持续对你全人类去享乐，但是享乐肯定娱乐至死

205
00:26:16.040 --> 00:26:17.800
说话人 1: 最后你这个退换，对

206
00:26:17.840 --> 00:26:19.040
说话人 2: 这是有可能出现

207
00:26:19.040 --> 00:26:32.130
说话人 3: 的现象，我觉得是这样的，这个事就是说第一个机器本身是人造的，他还我不用太去担心他控制人，但是制造机器这些人他在背后控制人，这是将来非常可怕

208
00:26:32.130 --> 00:26:35.890
说话人 3: 就是说你说这整个城市是一个大的机器，或者整个国家世界上
