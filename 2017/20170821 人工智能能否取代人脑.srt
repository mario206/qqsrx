
1
00:00:11.240 --> 00:00:17.880
说话人 1: 锵锵三人行，今天这个作为老腊肉很开心陪着你们才子才女

2
00:00:17.880 --> 00:00:20.560
说话人 2: 哈哈哈，学渣学霸

3
00:00:20.640 --> 00:00:23.800
说话人 1: 我觉得警方性好真的是很好是吧

4
00:00:23.800 --> 00:00:25.880
说话人 1: 对，好警方多好是吧

5
00:00:26.320 --> 00:00:29.040
说话人 1: 这个北京折叠把咱们都看折叠了是吧

6
00:00:29.080 --> 00:00:30.480
说话人 1: 对，你是不是粉丝

7
00:00:30.520 --> 00:00:35.080
说话人 2: 我是在获得那个鱼哥奖之前我就读过这个，这一篇的什么

8
00:00:35.080 --> 00:00:36.720
说话人 1: 都显得你先知先觉

9
00:00:36.720 --> 00:00:39.320
说话人 2: 不是，这是因为我是这个豆瓣用户嘛

10
00:00:39.320 --> 00:00:47.260
说话人 2: 我不是之前说过，但豆瓣网友就很爱这片，所以在很久之前就把这篇给推火了，但是这个我没想到我们这么的鲜知鲜血

11
00:00:47.420 --> 00:00:49.500
说话人 2: 哎，就这么多年一直以为生活在角落里

12
00:00:49.500 --> 00:00:49.660
说话人 2: 面

13
00:00:49.700 --> 00:00:50.140
说话人 2: 对

14
00:00:50.140 --> 00:00:55.980
说话人 1: 而且跟警方一聊，真是这个聊的投机在正在，现在正在运，能说吗

15
00:00:56.240 --> 00:01:06.470
说话人 1: 正在酝酿这个，写一个跟古文明起源有关的科幻大作，而且人家警方还准备拍科幻电影了

16
00:01:07.060 --> 00:01:16.420
说话人 3: 我对电影的介入是只在这个故事层面的，并没有介入到后面的剧本拍摄，导演这些还没有，还不会协助

17
00:01:16.540 --> 00:01:32.520
说话人 3: 我觉得作家就是作家，作家不是太能够做那些专业的事情，但是如果有这个科幻影视剧的剧组愿意拍摄我的故事，或者说是愿意让我再给他们继续创作一个故事的话，这个层面我是可以去做

18
00:01:32.520 --> 00:01:32.640
说话人 1: 的

19
00:01:32.680 --> 00:01:36.240
说话人 1: 嗯，好，我开始招商，哈哈哈

20
00:01:36.240 --> 00:01:37.040
说话人 2: 我开始做宣传

21
00:01:37.040 --> 00:01:41.400
说话人 1: 哈哈哈，不过最近你出的新书好像是跟人工智能有关

22
00:01:41.440 --> 00:01:44.640
说话人 1: 对，所以我就得请你这专家来聊聊了

23
00:01:45.480 --> 00:01:53.080
说话人 1: 这个格子你最近注意到没有，阮寅孙正义在我心目中那就是个大神

24
00:01:53.120 --> 00:01:54.200
说话人 1: 嗯，传奇人物

25
00:01:54.200 --> 00:01:54.480
说话人 1: 什么

26
00:01:54.480 --> 00:01:57.360
说话人 1: 这是马发现了马云都给他借钱是吧

27
00:01:57.360 --> 00:02:04.040
说话人 1: 对对，就这么大的一个大投资，而且我在日本都听说过他当年很多这个传奇故事

28
00:02:04.040 --> 00:02:07.550
说话人 1: 据说这个人这个子不高，简直就是非常矮，是吧

29
00:02:07.550 --> 00:02:14.550
说话人 1: 哈哈哈，但是就是这个不同凡响，但是我觉得他这个人很了不起哈

30
00:02:14.590 --> 00:02:19.340
说话人 1: 嗯，可是最近关于他的一个新闻就是他出席一个什么一个什么会吧

31
00:02:19.340 --> 00:02:25.980
说话人 1: 最近的出席，七月二十几号出席一个会，他这个会上讲的话却让我觉得这个人不太庄重

32
00:02:25.980 --> 00:02:32.720
说话人 1: 哈哈哈，简直是，我觉得他一个很雀跃，很雀跃，甚至就是我觉得是疯了

33
00:02:32.920 --> 00:02:54.410
说话人 1: 就是说，唉，人工智能比你们科幻听着还科幻，就是全球几百位人工智能科学家，不是预测这个起点还是叫基点，起点就是人工智能这个比肩人类智能的那个点，一般说他们的最大概率的说的预测的中位年是 2040 年

34
00:02:54.450 --> 00:02:56.370
说话人 2: 现在说 206040 都有的

35
00:02:56.450 --> 00:02:56.690
说话人 2: 对

36
00:02:56.770 --> 00:03:04.060
说话人 1: 孙正义说 2030 年，甚至就是说明年，哈哈哈， 2018 年

37
00:03:04.100 --> 00:03:14.740
说话人 1: 然后他说我现在成立了一个全球跟几个基金，跟阿拉伯什么什么基金成立了一个 1000 亿美元的这么一个基金，这是全球最大的基金

38
00:03:14.990 --> 00:03:20.830
说话人 1: 他说花了几百亿美元已经买了一个叫 AIM 是什么你知道吧

39
00:03:20.870 --> 00:03:33.310
说话人 1: 嗯，不知道， AIM 就做芯片的，对，做芯片的这么一个，然后他就说将来在你的鞋上，鞋，在你鞋上装个芯片，他说你能想得到吗

40
00:03:33.630 --> 00:03:35.350
说话人 1: 你的脚比你脑袋都聪明

41
00:03:36.230 --> 00:03:37.590
说话人 1: 疯了这个人，我觉得，我

42
00:03:37.590 --> 00:03:38.870
说话人 2: 其实我觉得也能实现

43
00:03:38.990 --> 00:03:42.510
说话人 2: 你不就是说人工智能和人的这个起点吗

44
00:03:42.510 --> 00:03:46.990
说话人 2: 那你先把人的智能降下来，比如他先疯掉，然后人工智能就超过他

45
00:03:46.990 --> 00:03:48.230
说话人 1: 了，情况现在正在发生

46
00:03:48.230 --> 00:03:48.270
说话人 1: 对

47
00:03:50.350 --> 00:03:51.270
说话人 3: 原来如此是个好

48
00:03:51.270 --> 00:03:51.630
说话人 1: 办法

49
00:03:51.670 --> 00:03:55.150
说话人 1: 对，而警方你看了孙正义这番狂论吗

50
00:03:55.150 --> 00:03:56.590
说话人 1: 看了，你信吗

51
00:03:56.630 --> 00:04:20.700
说话人 3: 我觉得他里面说的所有东西都很现实，没有什么太狂，问的地方就是他没有去做非常强的推论，就是强人工智能，超人工智能它其实都没有推，他现在真的是在推的，都只是在这个弱人工智能，就是专业领域的人工智能的发展，它所有说的技术都是很现实的，过不了多少年就能够实现的一些东西

52
00:04:20.940 --> 00:04:46.790
说话人 3: 所以现在其实肯定可以实现的，包括各种各样的越来越好的这些云图像识别技术，还有一些系统优化，把这些整个工业产业流程做一些优化，还有就是这个机器设备可以去参与到这个生产加工的很多过程里面，还有物联网，就未来的各个，包括这个可能也会是变成一个智能相连的，这个也都不难，很容易

53
00:04:46.990 --> 00:04:59.710
说话人 3: 然后还有接下来的就是可能这个人工智能，因为这分布式计算、大数据学习，他可以把很多的这些终端的数据拿过来，再去做很多的研究，给人提很多的生活建议

54
00:04:59.870 --> 00:05:14.850
说话人 3: 就这些真的是 5 到 10 年就会发生的事情，他离我们说的那种非常困难的强人工智能、超人工智能其实还远，但是他孙正义所讲的这些事情都是很实实在在的技术，都是很快就

55
00:05:14.850 --> 00:05:27.440
说话人 1: 能够实现，你看到的都是现实的，我看到的都是狂想，就是你比如说他讲了就是说人脑，就他讲话里他说人脑有 300 亿个脑细胞，我发现这个数字一直也在变动中

56
00:05:27.440 --> 00:05:32.160
说话人 1: 对，我过去听到的时候 1000 亿个孙正义真是给减了700700

57
00:05:32.160 --> 00:05:35.240
说话人 2: 亿，他说不信你数，哈哈哈

58
00:05:35.240 --> 00:05:38.380
说话人 1: 所以人类可能是在孙正义倡导下越来越蠢

59
00:05:38.380 --> 00:06:12.680
说话人 1: 对对对，这个孙权义说人脑起点来临 300 亿脑细胞，他说这些脑细胞之间的这个连接就是这个晶体管，晶体管就是这个像电脑那个二进位置的连接方式，就是连接断开，连接断开，他说咱们大脑就是这么运作的，那么就是二进位置，他说这个可以以此类推到晶体管，他说那么现在的晶体管已经造成，也就说一个晶，一个芯片里头超过 300 亿的，这个就是指 300 亿单位，我也不知是什么，就指日可期

60
00:06:13.080 --> 00:06:17.200
说话人 1: 那他这个意思就是说那可以超过人脑

61
00:06:18.420 --> 00:06:24.020
说话人 3: 但是人脑和这个就是电子设备有一个很大不一样，就是人脑这种灵活性就生物型

62
00:06:24.300 --> 00:06:50.010
说话人 3: 你知道神经元细胞它很大的一个特点是它两个细胞之间确实是像那种零一连接断开，但是这一个神经元的这个树突上面，它可以随时长出一些新的连接，可能我这个神经元和另外一个神经元啪就搭上了，然后搭上以后这连接如果稳固了，就成了一个新的连接，他就还可以跟他也连接断开，所以这样的话就是一个

63
00:06:50.010 --> 00:06:51.490
说话人 1: 芯片是做不到的

64
00:06:51.490 --> 00:07:16.280
说话人 3: 就是对一个神经元，他其实在他的一生里面他会不断的产生很多新的连接，他可能今天我和你连接，明天我和他连接，然后就是它会有大量的这些新的连接产生，然后也会有原来的连接可能就弱了就给断掉了，所以它并不是说两个神经元之间在不断的发生信号，它是每个神经元都有可能跟其他的大量神经元就是去建立新的连接

65
00:07:16.480 --> 00:07:18.280
说话人 3: 这有一个什么样的好处

66
00:07:18.280 --> 00:07:49.610
说话人 3: 就是其实人它是可以有这种大量的跳跃的联想，就是我可能今天坐在这里喝了这杯茶，然后我除了想头脑中想到的是跟您二位的谈话，我可能因为这杯茶我就想到了我和另外一个人的谈话，对，然后跟那个人的谈话的时候，当时这杯茶起了一个什么作用，然后又根据当时的话题我又想到另外一件事，这个事情其实没有任何逻辑联系，但是就是通过这个查他这个神经元，他也跟其他的神经元搭上线，所以我们就是有很多这种跳跃，我们

67
00:07:49.610 --> 00:07:51.450
说话人 1: 聊天就是这样的

68
00:07:51.450 --> 00:07:53.050
说话人 2: 然后就是枪枪的本质

69
00:07:53.050 --> 00:08:00.210
说话人 3: 特别，所以这就是造成了人，他其实一是有这个通识系统，二是人可以跨专业，就是懂好几个专业

70
00:08:00.290 --> 00:08:06.490
说话人 3: 现在你那癌症的神经不人工智能他其实不懂下围棋，他也不可能懂下围棋

71
00:08:06.490 --> 00:08:22.290
说话人 3: 对，懂下围棋的人工智能他其实不懂去做优化，就是去优化一个这个化学系统，但是一个人的话他是非常容易跨领域的那个了解这些事，就是这个神经元，他在不断的产生新的突触连接

72
00:08:22.330 --> 00:08:22.970
说话人 3: 那格子

73
00:08:22.970 --> 00:08:25.450
说话人 1: 你觉得我怎么觉得我的电脑能做到这个吗

74
00:08:25.450 --> 00:08:26.890
说话人 1: 将来我怎么觉得我

75
00:08:26.890 --> 00:08:28.450
说话人 2: 除了干新闻别的也干不了呢

76
00:08:28.450 --> 00:09:08.950
说话人 2: 哈哈哈哈哈哈，开玩笑，就是说其实我因为这文科生什么也不懂，所以就去打听了一下人工智能这个方面的比较前沿的一些朋友，他们就是给我的一传递一个明确的观点，很类似就说现在人工智能是看听你要具体单向比的，确实都接近或者超过人，这个没的说，但是想没有就是说你把这些都融合到一块，像人一样去想他没有就是因为这个，因为大家对人工智能有一个基本的一个判断，就是一派是这个悲观的一派是这个乐观的，悲观的那一派就特别的怕说，噢，你人工智能如果真的超越人之后，那他其实就不太需要你了，对吧

77
00:09:08.990 --> 00:09:19.380
说话人 2: 你尤其是如果咱们这些人就是最后我们能做的事比人工智能反而少了的时候，人工智能它其实在伦理上它没有必要留着你这些人

78
00:09:19.820 --> 00:09:28.460
说话人 2: 所以我前一阵我还在说嘛，我说这个未来人工智能真的统治了人类社会，把人类社会开始赶尽杀绝的时候，只有咱们师兄弟能活

79
00:09:28.780 --> 00:09:33.430
说话人 2: 嗯，因为咱们是最后拍马屁的那些人，哈哈哈，就是咱们是马屁界的一股清流

80
00:09:33.430 --> 00:09:36.150
说话人 1: 哈哈哈，最先消失的就是文科生

81
00:09:36.150 --> 00:09:39.430
说话人 2: 哈哈哈，咱们唯一的作用能逗人一乐知道吗

82
00:09:39.430 --> 00:09:39.630
说话人 2: 不是

83
00:09:39.870 --> 00:09:50.390
说话人 1: 再说这个，你说的这个据我所知也是一个未来人工智能的开发方向，他们好像有这么几个研究方向，当然距离还很远

84
00:09:50.590 --> 00:10:13.310
说话人 1: 一个就是说直接就是这个模拟人脑，不记得是，甚至有人提出那么一种理论，就是说假如把人脑这个就切片切片，切成最薄的这个片，那么这实际上完全复制它用，当然是用这个硅就硅生物了，这电脑是一种硅生物了，哎，完全复制它，那它是不是能等同于人脑

85
00:10:13.590 --> 00:10:35.440
说话人 1: 还有一种是就是模拟人脑的演化，这就是像你刚才所说的，就是说反正我看他们这个科技文章介绍就是说将来也有望培养出一个这个神经元，或者说一个什么，管他在自我学习的过程中，他一会连这个我不会

86
00:10:35.480 --> 00:10:49.940
说话人 1: 这我上次我们在另一个节目里，就是香港大学计算机系的那个杨强教授就讲，就说现在他们研究的是叫迁移学习，就是关于你说的 Alphago 只会下围棋吗

87
00:10:49.940 --> 00:10:51.220
说话人 1: 对，将来就不一定了

88
00:10:51.220 --> 00:10:56.780
说话人 1: 嗯，他们现在研究的是可以他用下围棋的能力，也可以转向另一个领域

89
00:10:57.080 --> 00:11:06.440
说话人 1: 他说现在那科技已经能够达到读取大脑的，就是说这个突触和那个突触，他说但是为什么距离很遥远

90
00:11:06.640 --> 00:11:13.530
说话人 1: 他说只能读取一个，比如说一个脑细胞或者一个神经元到一个神经元的一次连接的这个信息

91
00:11:13.770 --> 00:11:28.540
说话人 1: 他说但是你想大脑里照孙正义说 300 亿，就是这个距离是非常遥远，但是遥远按照那个，比如说摩尔定律，只要可以走出第一步，它的成长有可能是非常快的

92
00:11:29.060 --> 00:11:36.700
说话人 3: 对，就是这里面有几个层面的事情，一个是这个模拟的这个大脑是不是跟人的大脑一样

93
00:11:36.850 --> 00:11:46.280
说话人 3: 但是另外还有一个问题是你刚才提到的这个看听等等各个领域里面现在不相容，未来是怎样

94
00:11:46.400 --> 00:11:59.480
说话人 3: 但是其实人类在这个就是通感这方面，尤其是这个行动触感，嗯，能够跟这个整个的看和听相结合，这方面是非常强的

95
00:11:59.610 --> 00:12:12.000
说话人 3: 所以人类的很多的对于事物的认识，实际上是和要和这个身体感知，和人物的和人的这个行动感知带来的这个印象，这些是要相结合起来的

96
00:12:12.160 --> 00:12:15.920
说话人 3: 这个对于人工智能它识别很多东西就非常困难，那太难了

97
00:12:15.920 --> 00:12:27.420
说话人 3: 对，像人工智能它看一个轮胎的话，它如果只是某一个轮胎的一个侧面的投影，然后他并不知道这个东西在运动过程中是什么样子，所以它就很难再还原

98
00:12:27.580 --> 00:12:42.670
说话人 3: 但是人类的话，它因为天生就有一些先天的对于这个事物重力大小这个位置这样的一些先天的感知，所以人类可能看到一个很片段的一个事物，就能够大概的推断出它一个全貌

99
00:12:42.790 --> 00:12:45.790
说话人 3: 所以人类其实从出生以后是小数据学习

100
00:12:45.950 --> 00:12:55.750
说话人 3: 刚才说的有一个这个人工智能跟人的这个未来的这个比对，那其实人工智能未来它就强烈的取决于要需要大数据

101
00:12:55.910 --> 00:13:09.630
说话人 3: 包括您说这个人工智能这个迁移性，它实际上这个深度学习的算法它是可以迁移的，它就是从这些大数据里面怎么提取特征，然后再到第二层我怎么来分析特征，最后第三层组合这样的一个方法

102
00:13:09.670 --> 00:13:17.670
说话人 3: 这个深度学习的方法它确实可以从一个领域到另外一个领域，但前提是我每一个领域都有大数据，然后再进行学习反馈等等

103
00:13:17.810 --> 00:13:32.130
说话人 3: 哎，可是实际上人真正的一个人在生活里面不是这样的，人是小数据学习的人是通过一件事儿就可以做出一个某一个推论，叫吃一堑长一智，我们没有说吃 100 万堑长一智的，哎

104
00:13:32.170 --> 00:13:45.120
说话人 3: 然后所以这样的话，其实一是人有很多先天的这个天生就加载的一些这个头脑功能，这个就像是我们先天就已经装载很多软件了，那我们这个软件自动就处理功能

105
00:13:45.320 --> 00:13:57.550
说话人 3: 第二是我们也确实有一些能够从这个很多小小量的这个小数据事件中去归因，然后去抽象，去这个提取出一个高层次的一个认知的

106
00:13:57.550 --> 00:13:59.430
说话人 1: 能力，他这个观点非常重要

107
00:13:59.430 --> 00:14:00.310
说话人 1: 咱们先去一下挂牌

108
00:14:00.790 --> 00:14:02.070
说话人 2: 这么重要

109
00:14:02.070 --> 00:14:44.610
说话人 1: 广告之后见，团，你看你们俩是神经元，我是那个通路，我从李志生给你连的文科生鸽子，就是我对警方这个观点很感兴趣

110
00:14:44.610 --> 00:14:49.890
说话人 1: 嗯，就是咱们这些年感觉已经被人工智能打败了，都已经颓了

111
00:14:50.000 --> 00:15:00.830
说话人 1: 但是你知道比如说这个图像识别，它这个机器学习，嗯，它就是看 10 万个猫狗的照片，嗯，它都有可能把猫认成狗

112
00:15:00.950 --> 00:15:07.500
说话人 1: 对，但是对于人类的小朋友来说，嗯，可能看几个猫狗，嗯，他就知道猫和狗

113
00:15:07.660 --> 00:15:15.220
说话人 1: 这就是说人还有一种这种能力，叫做用咱们文科生的语言呐，叫一叶落而知秋

114
00:15:15.420 --> 00:15:15.860
说话人 1: 嗯，就是

115
00:15:15.980 --> 00:15:23.160
说话人 1: 唉，咱们讲举一反三就能反三，闻一对就能知识，嗯，是吧

116
00:15:23.160 --> 00:15:27.840
说话人 1: 嗯，他不是说大数据，咱们恰恰是这种小数据学习，唉，这挺

117
00:15:27.840 --> 00:15:28.200
说话人 2: 牛的

118
00:15:28.200 --> 00:15:40.000
说话人 2: 我现在确实感觉人和人工智能在两条路上走，你看我们的优缺点都特别明显，人刚才说到人比人工智能这个优点，就是我们这些小数据就可以搞定这个万事万物，几乎，对吧

119
00:15:40.300 --> 00:15:51.140
说话人 2: 但是我们有一个问题就是我们也记不住数据，不要说技术大数据，我们小数据也记不住，这唐诗宋词三百首，很小的数据几百k，有人记住吗

120
00:15:51.450 --> 00:15:58.450
说话人 3: 对，但是其实现在也有神经学家去研究说遗忘本身是一个优势，就是，唉，这

121
00:15:58.450 --> 00:16:02.210
说话人 1: 我很感兴趣，这个，我这我岁数正到的，对这感兴趣

122
00:16:02.250 --> 00:16:31.920
说话人 3: 说其实遗忘从你换一个角度说是你能够选择记住最重要的东西，因为你这个人脑毕竟不像是这个计算机，你无限存储等等，就是那么你在这个人脑你就像要好刚用在刀刃上，所以实际上是遗忘是在人脑的一个机制，就是不断的把你现在的这个叫工作记忆，然后再用到一些对于你自己的人生更加很重要的事情

123
00:16:32.040 --> 00:16:38.120
说话人 3: 所以其实遗忘它是一种选择，记忆就是你你去选择了记住了那些你最重要的东西

124
00:16:38.300 --> 00:16:38.930
说话人 3: 这然后呢

125
00:16:38.930 --> 00:16:56.170
说话人 3: 有很就像刚才说那神经元它搭上线，然后你要是反复的搭这两根线，它这个建立的很稳，就是很稳固，你就能不断的通上，然后有的可能搭上过一次线，然后以后再也没用了，然后这个这线就断了，然后它这神经元就又给砍掉了

126
00:16:56.330 --> 00:17:23.970
说话人 3: 所以其实人脑在最开始的几年里面会大量生出很多突触，后来有一个大量的侃侃的过程，大概六七岁的时候，这个时候慢慢就会记住对于他来讲很重要的这些东西，然后包括大脑的工作记忆，工作记忆就有点像是一个内存，就是现在正在干的这些事，那大脑的工作记忆现在人们就认为只有四个到七个空间，那就是您头脑中正在想的这个事儿，你只能腾出来给你最重要的事儿

127
00:17:24.210 --> 00:17:36.370
说话人 3: 你要是就是毫无区分的，我所有事情都记住了，我可能记了无数的唐诗宋词，我连这个 300 首之外的，我这个记了5万首，但是那你怎么能够说我什么东西是最重要的

128
00:17:36.370 --> 00:17:38.490
说话人 3: 我大脑要记住要去思考

129
00:17:38.490 --> 00:17:53.200
说话人 1: 的东西，而且就大脑会选择，而且大脑会总结，就是他说的这个，你不是这个，听了那个尤尔克拉利最近在中国那演讲，对，我都想起尤尔克拉利的书里写的，我也有一点我很感兴趣，他就说那个研究什么呢

130
00:17:53.200 --> 00:18:04.200
说话人 1: 比如说两组学生，你看我们人其实有两种，一种叫同时经历，就比如说现在咱们做节目，每时每刻都产生感觉

131
00:18:04.320 --> 00:18:13.070
说话人 1: 对，但是到明天我们想起我们这次聊天，我们脑子里也会有一个记忆，嗯，这两个记忆我们以为是一样的，其实是不一样的

132
00:18:13.070 --> 00:18:31.290
说话人 1: 对，比如说他做一个实验，就两组学生，假如说两组学生都把这个手放在 12 度的水里放 10 分钟，但是其中一组放完这个十分钟之后，再让他在，比如说 15 度的水里放，比如说五分钟

133
00:18:31.820 --> 00:18:39.130
说话人 1: 然后最后再问他们，就是刚才那 10 分钟，刚才你放在 12 度水里那 10 分钟你们的感觉是多少度

134
00:18:39.570 --> 00:18:40.170
说话人 1: 那么呢

135
00:18:40.530 --> 00:18:45.810
说话人 1: 就后来没往热水里放的那组学生回答就是 12 度

136
00:18:45.850 --> 00:18:47.130
说话人 1: 不，比如说就 12 度

137
00:18:47.130 --> 00:18:53.820
说话人 1: 嗯，但是最后放了 5 分钟热水的那个学生，他会回答，之前的那 10 分钟是13

138
00:18:53.820 --> 00:18:56.300
说话人 3: 度，他会那边

139
00:18:56.380 --> 00:19:01.460
说话人 1: 问高手就是他的意思是说尤尔克莱利的意思是说，通过这个实验可以说明什么呢

140
00:19:01.780 --> 00:19:09.500
说话人 1: 人哪，大脑也许是电脑这个容量，它不会保留每分每秒每一直这么记

141
00:19:09.580 --> 00:19:24.160
说话人 1: 对，它实际上在你脑子里就像个总结报告，年度总结报告是年终总结报告，你年终总结报告他也许取的是头中尾，所以你尾巴上有一个更好的回忆

142
00:19:25.100 --> 00:19:33.540
说话人 1: 所以说格子就是说这个恋爱不管中间多么苦，最后结果甜蜜一点，我告诉你，将来想起来会觉得，唉，好像没那么苦

143
00:19:33.540 --> 00:19:34.540
说话人 2: 还有结果甜蜜的

144
00:19:34.540 --> 00:19:41.060
说话人 2: 哈哈哈，没有，我刚就想说这个，怎么忘掉那么多，就忘不掉前任，这个人的大脑就公，这个就不太科学，对吧

145
00:19:42.660 --> 00:19:51.060
说话人 3: 但是那个对于你在接下来的再进入感情生活这段经历本身是非常重要的，所以它的这个重要性优先级是第一位的

146
00:19:51.240 --> 00:20:29.820
说话人 3: 就是您刚才说的这个头脑的思维过程，实际上就是人脑的这个记忆，它不像是这个电脑上的记忆，它就是记进去了，就是当时的这个死的，它像是某一个东西放在这个硬盘里，就像放一框里一样，人脑的记忆它其实是一个过程，到现在为止其实人们也没有发现说人脑的记忆是存在大脑里的什么地方的，有一个地方就是专门放记忆的，没有人脑的记忆，其实一个回忆的过程跟大脑好多个脑区都有关系，所以他其实回忆就是从经历了一下，就是你哪怕只是想这个事，他也是那些神经细胞他重新经历了，而且好像是他会能被修改

147
00:20:29.820 --> 00:20:32.460
说话人 1: 对，修改，而且好像是回忆一次修改一次

148
00:20:32.550 --> 00:20:34.340
说话人 2: 对，而且是人和人还不一样

149
00:20:34.380 --> 00:20:40.860
说话人 2: 对，是有些人是特别擅长时间的记忆，有些人是特别适合短时间的记忆，我觉得我就这么一斤鱼

150
00:20:40.860 --> 00:20:41.980
说话人 2: 哈哈哈，是吧

151
00:20:41.980 --> 00:20:46.660
说话人 2: 对，短时间的我真是还马上真能记住，但是过了一阵就是

152
00:20:46.900 --> 00:20:49.100
说话人 1: 对，那说明你还年轻，是吧

153
00:20:49.100 --> 00:20:55.200
说话人 1: 你要是比我还老的时候，你就是昨天都记不住了，昨天的事记不住，小时候的事全记得

154
00:20:55.200 --> 00:21:13.140
说话人 1: 哈哈哈，你看我刚才这个又想起警方的这个折叠了

155
00:21:13.140 --> 00:21:31.320
说话人 1: 嗯，就最近这个尤瓦尔他来中国演讲，又有人提起你这个小说，因为他这个里边讲了一种阶级，讲了一种就是说未来的这种无用阶级，就是说我觉得人类要警惕，就是说到时候大部分没用的人连知识更新都来不及

156
00:21:31.400 --> 00:21:38.380
说话人 1: 我看最近这个警方有一个演讲，就是人家家长们也都问他说，那这孩子将来该干什么

157
00:21:38.500 --> 00:21:47.980
说话人 1: 唉，赵孙正义说眼瞅着明年就来了，你，你这事是破到眼前了，就是说给孩子选哪条路，现在看来是很重要的，这个

158
00:21:47.980 --> 00:21:51.940
说话人 2: 有可能，人工智能照这么发展下去，给孩子选哪条路他以后都得适应

159
00:21:51.940 --> 00:21:53.620
说话人 2: 哈哈哈，这是认真不

160
00:21:53.660 --> 00:21:53.700
说话人 2: 不

161
00:21:53.700 --> 00:21:55.260
说话人 1: 他有招啊，他有几条路

162
00:21:55.260 --> 00:21:58.880
说话人 1: 你你你你，你好像总结了几类还能有饭吃啊

163
00:21:59.040 --> 00:22:07.400
说话人 3: 就其实是可能，这不是某一个行业的问题，像过去的话，你可能想我选择一个好的行业，我在这个行业里面发展就可以了

164
00:22:07.560 --> 00:22:18.600
说话人 3: 但现在的问题是可能每一个行业都受到同等的冲击，每一个行业里面都有一些职位会大量的减少，但是每个行业里面都还有其他的职位会留下

165
00:22:18.720 --> 00:22:25.940
说话人 3: 因为接下来的话，比如我们这个节目组，我们其实是仍然会有这个节目组，仍然会有工作人员，但是以前我们

166
00:22:25.980 --> 00:22:27.380
说话人 2: 机器人了，各位都是

167
00:22:27.380 --> 00:22:37.860
说话人 3: 机器，没有，但是以前可能得需要，可能 3 个人去寻找，说最近有什么热点话题，你去网上搜搜新闻，你给总结，或者是你去找找，嗯

168
00:22:37.860 --> 00:22:44.180
说话人 3: 谁去看看嘉宾，你去搜索一下嘉宾，就光这件事以前可能就要 3 个人干，我现在就

169
00:22:44.180 --> 00:23:01.270
说话人 1: 不用，我现在已经完全可以断定，即便我是文科生，就我们这仨哥们，明年可能真的就是因为你看它这个机器，它这个摄像机是完全可以没人的，这个导演在后边这么一弄，转转走走，在哪用他们呢

170
00:23:01.270 --> 00:23:01.350
说话人 1: 师兄

171
00:23:01.350 --> 00:23:04.110
说话人 2: 这现在还录着，小心黑屏，哈哈哈

172
00:23:06.250 --> 00:23:08.730
说话人 3: 但是什么样的人是不难以取代呢

173
00:23:08.850 --> 00:23:21.730
说话人 3: 就是我们想说如果我们现在要策划一档这个节目的一些有创新性的东西，或我做一档新节目，这个新节目没有这么标准化，比如说这些机位都固定了，但这个新节目我们到底要做成几个人的

174
00:23:21.810 --> 00:23:23.570
说话人 3: 什么什么形式的主持人

175
00:23:23.570 --> 00:23:24.850
说话人 3: 是跳跳蹦蹦上来的

176
00:23:24.850 --> 00:23:25.250
说话人 3: 还是主持人

177
00:23:25.250 --> 00:23:26.290
说话人 1: 创意和灵感

178
00:23:26.290 --> 00:23:26.570
说话人 1: 对

179
00:23:26.610 --> 00:23:30.490
说话人 3: 和创意和策划，以及去和用户沟通，那我做成什么样的

180
00:23:30.490 --> 00:23:32.370
说话人 3: 你喜欢，然后我怎么样来打动你

181
00:23:32.650 --> 00:23:45.370
说话人 3: 然后另外就是我一些创新，然后再加上整个的这个策划统筹安排，就所有的这些从 0 到 1 的这个过程，其实甚至 0 到 100 都还是需要人来，我觉得应该是从 100 到1万，可能就是

182
00:23:45.370 --> 00:23:53.940
说话人 2: 你说到那会了，现在每个单位里面恐怕大家的感觉都是怎么出主意的人这么多，干活的人少，就是我们从来还不太学出

183
00:23:53.940 --> 00:23:55.820
说话人 1: 主意的多，出靠谱主意的少

184
00:23:55.820 --> 00:24:06.180
说话人 1: 哈哈哈，就要我这么说，我觉得应该让孩子多学艺术，他这个艺术比较促发他的审美灵感、想象力

185
00:24:06.260 --> 00:24:18.570
说话人 3: 其实是在任何一个领域里面，哪怕是语数外，还有这些理科，还有就是可能一些社科其实都可以按照像艺术那种方式，以一个创意性的方式去学习

186
00:24:18.690 --> 00:24:39.120
说话人 3: 这也是为什么我在给那些家长讲的时候，我要提到说我自己现在在做这个儿童教育项目，我们就是做创造力教育，我们其实不做特别深入的具体某一个学科，我们就是让他一种创造性的学习，用创造性的方式去学习这种阅读写作，用创造性的方式去学科学创造性的方式

187
00:24:39.160 --> 00:24:45.440
说话人 3: 就比如我们有一个科学课，是让这个孩子他们自己来设计一个月球基地，自己设计一个月球王国

188
00:24:45.560 --> 00:25:08.880
说话人 3: 但是在这个过程中你就需要学习月球上的环境，什么是真空气、大气，然后衣食住行的这些东西，重力在这个过程中你学这些东西，但是并不是说我要学完了以后给是一个课这个考试，而是说你这些知识都是像一个食材一样，那么炒什么菜由你来决定，所以就让他们还是能够很大程度

189
00:25:08.880 --> 00:25:11.440
说话人 1: 但是这样培养出来的神童们怎么参加

190
00:25:11.440 --> 00:25:12.120
说话人 3: 高考

191
00:25:12.670 --> 00:25:20.310
说话人 3: 其实在这种过程中学学到的知识反而会是比较能够，就是能够学到心理去的知识

192
00:25:20.630 --> 00:25:31.630
说话人 3: 就是包括比如说像我写小说的时候，我可能因为这个领域的东西我不懂，我要去看书，那我因为在小说里面要用，我是真的要学懂了我才能用

193
00:25:31.750 --> 00:25:39.860
说话人 3: 所以其实往往在写作过程中学的一些知识记忆还会比较牢固，比这个考试之前为了考试背的知识记忆还更牢固一些

194
00:25:39.860 --> 00:25:41.220
说话人 1: 又说回文科生了

195
00:25:41.220 --> 00:25:46.260
说话人 2: 我是发现有点希望，我是发现工作之后记住的东西比这个工作之前是十几年都多

196
00:25:46.260 --> 00:25:46.820
说话人 1: 这是真的

197
00:25:46.820 --> 00:25:50.700
说话人 1: 格子，你这么年轻，你真，你不怕你到我这岁数的时候被淘汰

198
00:25:50.700 --> 00:26:05.080
说话人 2: 了，我特别怕，因为我就在想，因为这个我以前在一些媒体实习的时候，已经发现他们在用这个这个已经写好的程序来报快速的新闻，比如体育比分，比如说这个中国的GDP，比如说股票的涨跌，对吧

199
00:26:05.160 --> 00:26:05.800
说话人 2: 非常简单

200
00:26:05.800 --> 00:26:06.080
说话人 1: 就可以写

201
00:26:06.080 --> 00:26:07.960
说话人 1: 现在新闻稿机器已经能写，很

202
00:26:07.960 --> 00:26:08.440
说话人 2: 容易写出来

203
00:26:08.440 --> 00:26:11.920
说话人 2: 我就在想这个以后新闻可能确实很好取代我们

204
00:26:12.120 --> 00:26:18.670
说话人 2: 但有一个问题，如果人工智能特别强大了之后，他万一就故意给你写假新闻，这人类能不能承担这个

205
00:26:18.670 --> 00:26:19.030
说话人 1: 代价

206
00:26:19.070 --> 00:26:23.030
说话人 1: 唉，那就属于人工智能会有阴谋，他这个应该还没有

207
00:26:23.030 --> 00:26:24.990
说话人 2: 对，我就特别怕他会想，现在

208
00:26:25.190 --> 00:26:31.030
说话人 3: 就这个关于人工智能有没有自主性，这也是一个特别大的话题，这个本身也可以，那个说到

209
00:26:31.190 --> 00:26:32.710
说话人 1: 上好有可能将来有吗

210
00:26:32.710 --> 00:26:32.990
说话人 1: 我不

211
00:26:32.990 --> 00:26:33.430
说话人 3: 觉得

212
00:26:33.530 --> 00:26:39.920
说话人 3: 就是这个又会涉及到人工智能和这个小孩的另一个区别，就是这个自主性的这个区别

213
00:26:40.120 --> 00:26:48.000
说话人 3: 那个孩子的有很多的就是特点，到目前为止，哪怕是再聪明的人工智能，他现在都还没有达

214
00:26:48.000 --> 00:26:49.400
说话人 1: 不到

215
00:26:49.400 --> 00:26:51.280
说话人 3: 就是他的那种自主性
